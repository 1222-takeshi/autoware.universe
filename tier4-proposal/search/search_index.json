{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"autoware.universe # This is one of the prototype repositories for Autoware Core/Universe that AWF agreed to create in the TSC meeting on 2021/11/17 . Please see autowarefoundation/autoware for more details.","title":"autoware.universe"},{"location":"#autowareuniverse","text":"This is one of the prototype repositories for Autoware Core/Universe that AWF agreed to create in the TSC meeting on 2021/11/17 . Please see autowarefoundation/autoware for more details.","title":"autoware.universe"},{"location":"common/autoware_utils/","text":"autoware_utils # Purpose # This package contains many common functions used by other packages, so please refer to them as needed.","title":"autoware_utils"},{"location":"common/autoware_utils/#autoware_utils","text":"","title":"autoware_utils"},{"location":"common/autoware_utils/#purpose","text":"This package contains many common functions used by other packages, so please refer to them as needed.","title":"Purpose"},{"location":"common/goal_distance_calculator/Readme/","text":"goal_distance_calculator # Purpose # This node publishes deviation of self-pose from goal pose. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description /planning/mission_planning/route autoware_auto_planning_msgs::msg::Route Used to get goal pose /tf tf2_msgs/TFMessage TF (self-pose) Output # Name Type Description deviation/lateral autoware_debug_msgs::msg::Float64Stamped publish lateral deviation of self-pose from goal pose[m] deviation/longitudinal autoware_debug_msgs::msg::Float64Stamped publish longitudinal deviation of self-pose from goal pose[m] deviation/yaw autoware_debug_msgs::msg::Float64Stamped publish yaw deviation of self-pose from goal pose[rad] deviation/yaw_deg autoware_debug_msgs::msg::Float64Stamped publish yaw deviation of self-pose from goal pose[deg] Parameters # Node Parameters # Name Type Default Value Explanation update_rate double 10.0 Timer callback period. [Hz] Core Parameters # Name Type Default Value Explanation oneshot bool true publish deviations just once or repeatedly Assumptions / Known limits # TBD.","title":"goal_distance_calculator"},{"location":"common/goal_distance_calculator/Readme/#goal_distance_calculator","text":"","title":"goal_distance_calculator"},{"location":"common/goal_distance_calculator/Readme/#purpose","text":"This node publishes deviation of self-pose from goal pose.","title":"Purpose"},{"location":"common/goal_distance_calculator/Readme/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"common/goal_distance_calculator/Readme/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"common/goal_distance_calculator/Readme/#input","text":"Name Type Description /planning/mission_planning/route autoware_auto_planning_msgs::msg::Route Used to get goal pose /tf tf2_msgs/TFMessage TF (self-pose)","title":"Input"},{"location":"common/goal_distance_calculator/Readme/#output","text":"Name Type Description deviation/lateral autoware_debug_msgs::msg::Float64Stamped publish lateral deviation of self-pose from goal pose[m] deviation/longitudinal autoware_debug_msgs::msg::Float64Stamped publish longitudinal deviation of self-pose from goal pose[m] deviation/yaw autoware_debug_msgs::msg::Float64Stamped publish yaw deviation of self-pose from goal pose[rad] deviation/yaw_deg autoware_debug_msgs::msg::Float64Stamped publish yaw deviation of self-pose from goal pose[deg]","title":"Output"},{"location":"common/goal_distance_calculator/Readme/#parameters","text":"","title":"Parameters"},{"location":"common/goal_distance_calculator/Readme/#node-parameters","text":"Name Type Default Value Explanation update_rate double 10.0 Timer callback period. [Hz]","title":"Node Parameters"},{"location":"common/goal_distance_calculator/Readme/#core-parameters","text":"Name Type Default Value Explanation oneshot bool true publish deviations just once or repeatedly","title":"Core Parameters"},{"location":"common/goal_distance_calculator/Readme/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"common/path_distance_calculator/Readme/","text":"path_distance_calculator # Purpose # This node publishes a distance from the closest path point from the self-position to the end point of the path. Note that the distance means the arc-length along the path, not the Euclidean distance between the two points. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description /planning/scenario_planning/lane_driving/behavior_planning/path autoware_auto_planning_msgs::msg::Path Reference path /tf tf2_msgs/TFMessage TF (self-pose) Output # Name Type Description ~/distance autoware_debug_msgs::msg::Float64Stamped Publish a distance from the closest path point from the self-position to the end point of the path[m] Parameters # Node Parameters # None. Core Parameters # None. Assumptions / Known limits # TBD.","title":"path_distance_calculator"},{"location":"common/path_distance_calculator/Readme/#path_distance_calculator","text":"","title":"path_distance_calculator"},{"location":"common/path_distance_calculator/Readme/#purpose","text":"This node publishes a distance from the closest path point from the self-position to the end point of the path. Note that the distance means the arc-length along the path, not the Euclidean distance between the two points.","title":"Purpose"},{"location":"common/path_distance_calculator/Readme/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"common/path_distance_calculator/Readme/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"common/path_distance_calculator/Readme/#input","text":"Name Type Description /planning/scenario_planning/lane_driving/behavior_planning/path autoware_auto_planning_msgs::msg::Path Reference path /tf tf2_msgs/TFMessage TF (self-pose)","title":"Input"},{"location":"common/path_distance_calculator/Readme/#output","text":"Name Type Description ~/distance autoware_debug_msgs::msg::Float64Stamped Publish a distance from the closest path point from the self-position to the end point of the path[m]","title":"Output"},{"location":"common/path_distance_calculator/Readme/#parameters","text":"","title":"Parameters"},{"location":"common/path_distance_calculator/Readme/#node-parameters","text":"None.","title":"Node Parameters"},{"location":"common/path_distance_calculator/Readme/#core-parameters","text":"None.","title":"Core Parameters"},{"location":"common/path_distance_calculator/Readme/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"control/shift_decider/","text":"Shift Decider # Purpose # shift_decider is a module to decide shift from ackermann control command. Inner-workings / Algorithms # Flow chart # Algorithms # Inputs / Outputs # Input # Name Type Description ~/input/control_cmd autoware_auto_control_msgs::msg::AckermannControlCommand Control command for vehicle. Output # Name Type Description ~output/shift_cmd autoware_auto_vehicle_msgs::msg::GearCommand Gear for drive forward / backward. Parameters # none. Assumptions / Known limits # TBD.","title":"Shift Decider"},{"location":"control/shift_decider/#shift-decider","text":"","title":"Shift Decider"},{"location":"control/shift_decider/#purpose","text":"shift_decider is a module to decide shift from ackermann control command.","title":"Purpose"},{"location":"control/shift_decider/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"control/shift_decider/#flow-chart","text":"","title":"Flow chart"},{"location":"control/shift_decider/#algorithms","text":"","title":"Algorithms"},{"location":"control/shift_decider/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"control/shift_decider/#input","text":"Name Type Description ~/input/control_cmd autoware_auto_control_msgs::msg::AckermannControlCommand Control command for vehicle.","title":"Input"},{"location":"control/shift_decider/#output","text":"Name Type Description ~output/shift_cmd autoware_auto_vehicle_msgs::msg::GearCommand Gear for drive forward / backward.","title":"Output"},{"location":"control/shift_decider/#parameters","text":"none.","title":"Parameters"},{"location":"control/shift_decider/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"localization/ndt/","text":"ndt # This package aims to absorb the differences of several NDT implementations and provide a common interface.","title":"ndt"},{"location":"localization/ndt/#ndt","text":"This package aims to absorb the differences of several NDT implementations and provide a common interface.","title":"ndt"},{"location":"localization/ndt_pcl_modified/","text":"ndt_pcl_modified # Purpose # This is a modification of PCL 's NDT. Modifications # You can get the Hessian matrix by getHessian(). You can get the estimated position for each iteration by getFinalTransformationArray(). It optimizes rotational axes first, then jointly optimizes rotational and translational axes. [experimental feature]","title":"ndt_pcl_modified"},{"location":"localization/ndt_pcl_modified/#ndt_pcl_modified","text":"","title":"ndt_pcl_modified"},{"location":"localization/ndt_pcl_modified/#purpose","text":"This is a modification of PCL 's NDT.","title":"Purpose"},{"location":"localization/ndt_pcl_modified/#modifications","text":"You can get the Hessian matrix by getHessian(). You can get the estimated position for each iteration by getFinalTransformationArray(). It optimizes rotational axes first, then jointly optimizes rotational and translational axes. [experimental feature]","title":"Modifications"},{"location":"localization/ndt_scan_matcher/","text":"ndt_scan_matcher # Purpose # ndt_scan_matcher is a package for position estimation using the NDT scan matching method. There are two main functions in this package: estimate position by scan matching estimate initial position via the ROS service using the Monte Carlo method Inputs / Outputs # Input # Name Type Description ekf_pose_with_covariance geometry_msgs::msg::PoseWithCovarianceStamped initial pose pointcloud_map sensor_msgs::msg::PointCloud2 map pointcloud points_raw sensor_msgs::msg::PointCloud2 sensor pointcloud Output # Name Type Description ndt_pose geometry_msgs::msg::PoseStamped estimated pose ndt_pose_with_covariance geometry_msgs::msg::PoseWithCovarianceStamped estimated pose with covariance /diagnostics diagnostic_msgs::msg::DiagnosticArray diagnostics points_aligned sensor_msgs::msg::PointCloud2 [debug topic] pointcloud aligned by scan matching initial_pose_with_covariance geometry_msgs::msg::PoseWithCovarianceStamped [debug topic] initial pose used in scan matching exe_time_ms autoware_debug_msgs::msg::Float32Stamped [debug topic] execution time for scan matching [ms] transform_probability autoware_debug_msgs::msg::Float32Stamped [debug topic] score of scan matching iteration_num autoware_debug_msgs::msg::Int32Stamped [debug topic] number of scan matching iterations initial_to_result_distance autoware_debug_msgs::msg::Float32Stamped [debug topic] distance difference between the initial point and the convergence point [m] initial_to_result_distance_old autoware_debug_msgs::msg::Float32Stamped [debug topic] distance difference between the older of the two initial points used in linear interpolation and the convergence point [m] initial_to_result_distance_new autoware_debug_msgs::msg::Float32Stamped [debug topic] distance difference between the newer of the two initial points used in linear interpolation and the convergence point [m] ndt_marker visualization_msgs::msg::MarkerArray [debug topic] markers for debugging monte_carlo_initial_pose_marker visualization_msgs::msg::MarkerArray [debug topic] particles used in initial position estimation Service # Name Type Description ndt_align_srv autoware_localization_srvs::srv::PoseWithCovarianceStamped service to estimate initial pose Parameters # Core Parameters # Name Type Description base_frame string Vehicle reference frame input_sensor_points_queue_size int Subscriber queue size ndt_implement_type int NDT implementation type (0=PCL_GENERIC, 1=PCL_MODIFIED, 2=OMP) trans_epsilon double The maximum difference between two consecutive transformations in order to consider convergence step_size double The newton line search maximum step length resolution double The ND voxel grid resolution [m] max_iterations int The number of iterations required to calculate alignment converged_param_transform_probability double Threshold for deciding whether to trust the estimation result omp_neighborhood_search_method int neighborhood search method in OMP (0=KDTREE, 1=DIRECT26, 2=DIRECT7, 3=DIRECT1) omp_num_threads int Number of threads used for parallel computing","title":"ndt_scan_matcher"},{"location":"localization/ndt_scan_matcher/#ndt_scan_matcher","text":"","title":"ndt_scan_matcher"},{"location":"localization/ndt_scan_matcher/#purpose","text":"ndt_scan_matcher is a package for position estimation using the NDT scan matching method. There are two main functions in this package: estimate position by scan matching estimate initial position via the ROS service using the Monte Carlo method","title":"Purpose"},{"location":"localization/ndt_scan_matcher/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"localization/ndt_scan_matcher/#input","text":"Name Type Description ekf_pose_with_covariance geometry_msgs::msg::PoseWithCovarianceStamped initial pose pointcloud_map sensor_msgs::msg::PointCloud2 map pointcloud points_raw sensor_msgs::msg::PointCloud2 sensor pointcloud","title":"Input"},{"location":"localization/ndt_scan_matcher/#output","text":"Name Type Description ndt_pose geometry_msgs::msg::PoseStamped estimated pose ndt_pose_with_covariance geometry_msgs::msg::PoseWithCovarianceStamped estimated pose with covariance /diagnostics diagnostic_msgs::msg::DiagnosticArray diagnostics points_aligned sensor_msgs::msg::PointCloud2 [debug topic] pointcloud aligned by scan matching initial_pose_with_covariance geometry_msgs::msg::PoseWithCovarianceStamped [debug topic] initial pose used in scan matching exe_time_ms autoware_debug_msgs::msg::Float32Stamped [debug topic] execution time for scan matching [ms] transform_probability autoware_debug_msgs::msg::Float32Stamped [debug topic] score of scan matching iteration_num autoware_debug_msgs::msg::Int32Stamped [debug topic] number of scan matching iterations initial_to_result_distance autoware_debug_msgs::msg::Float32Stamped [debug topic] distance difference between the initial point and the convergence point [m] initial_to_result_distance_old autoware_debug_msgs::msg::Float32Stamped [debug topic] distance difference between the older of the two initial points used in linear interpolation and the convergence point [m] initial_to_result_distance_new autoware_debug_msgs::msg::Float32Stamped [debug topic] distance difference between the newer of the two initial points used in linear interpolation and the convergence point [m] ndt_marker visualization_msgs::msg::MarkerArray [debug topic] markers for debugging monte_carlo_initial_pose_marker visualization_msgs::msg::MarkerArray [debug topic] particles used in initial position estimation","title":"Output"},{"location":"localization/ndt_scan_matcher/#service","text":"Name Type Description ndt_align_srv autoware_localization_srvs::srv::PoseWithCovarianceStamped service to estimate initial pose","title":"Service"},{"location":"localization/ndt_scan_matcher/#parameters","text":"","title":"Parameters"},{"location":"localization/ndt_scan_matcher/#core-parameters","text":"Name Type Description base_frame string Vehicle reference frame input_sensor_points_queue_size int Subscriber queue size ndt_implement_type int NDT implementation type (0=PCL_GENERIC, 1=PCL_MODIFIED, 2=OMP) trans_epsilon double The maximum difference between two consecutive transformations in order to consider convergence step_size double The newton line search maximum step length resolution double The ND voxel grid resolution [m] max_iterations int The number of iterations required to calculate alignment converged_param_transform_probability double Threshold for deciding whether to trust the estimation result omp_neighborhood_search_method int neighborhood search method in OMP (0=KDTREE, 1=DIRECT26, 2=DIRECT7, 3=DIRECT1) omp_num_threads int Number of threads used for parallel computing","title":"Core Parameters"},{"location":"map/lanelet2_extension/","text":"lanelet2_extension package # This package contains external library for Lanelet2 and is meant to ease the use of Lanelet2 in Autoware. Lanelet Format for Autoware # Autoware uses extended Lanelet2 Format for Autoware, which means you need to add some tags to default OSM file if you want to fully use Lanelet2 maps. For details about custom tags, please refer to this document . Code API # IO # Autoware OSM Parser # Autoware Lanelet2 Format uses .osm extension as original Lanelet2. However, there are some custom tags that is used by the parser. Currently, this includes: overwriting x,y values with local_x and local_y tags. reading <MapMetaInfo> tag which contains information about map format version and map version. The parser is registered as \"autoware_osm_handler\" as lanelet parser Projection # MGRS Projector # MGRS projector projects latitude longitude into MGRS Coordinates. Regulatory Elements # Autoware Traffic Light # Autoware Traffic Light class allows you to retrieve information about traffic lights. Autoware Traffic Light class contains following members: traffic light shape light bulbs information of traffic lights stopline associated to traffic light Utility # Message Conversion # This contains functions to convert lanelet map objects into ROS messages. Currently it contains following conversions: lanelet::LaneletMapPtr to/from autoware_auto_mapping_msgs::msg::HADMapBin lanelet::Point3d to geometry_msgs::Point lanelet::Point2d to geometry_msgs::Point lanelet::BasicPoint3d to geometry_msgs::Point Query # This module contains functions to retrieve various information from maps. e.g. crosswalks, trafficlights, stoplines Utilities # This module contains other useful functions related to Lanelet. e.g. matching waypoint with lanelets Visualization # Visualization contains functions to convert lanelet objects into visualization marker messages. Currently it contains following conversions: lanelet::Lanelet to Triangle Markers lanelet::LineString to LineStrip Markers TrafficLights to Triangle Markers Nodes # lanelet2_extension_sample # Code for this explains how this lanelet2_extension library is used. The executable is not meant to do anything. autoware_lanelet2_extension # This node checks if an .osm file follows the Autoware version of Lanelet2 format. You can check by running: ros2 run lanelet2_extension autoware_lanelet2_validation _map_file: = <path/to/map.osm>","title":"lanelet2_extension package"},{"location":"map/lanelet2_extension/#lanelet2_extension-package","text":"This package contains external library for Lanelet2 and is meant to ease the use of Lanelet2 in Autoware.","title":"lanelet2_extension package"},{"location":"map/lanelet2_extension/#lanelet-format-for-autoware","text":"Autoware uses extended Lanelet2 Format for Autoware, which means you need to add some tags to default OSM file if you want to fully use Lanelet2 maps. For details about custom tags, please refer to this document .","title":"Lanelet Format for Autoware"},{"location":"map/lanelet2_extension/#code-api","text":"","title":"Code API"},{"location":"map/lanelet2_extension/#io","text":"","title":"IO"},{"location":"map/lanelet2_extension/#autoware-osm-parser","text":"Autoware Lanelet2 Format uses .osm extension as original Lanelet2. However, there are some custom tags that is used by the parser. Currently, this includes: overwriting x,y values with local_x and local_y tags. reading <MapMetaInfo> tag which contains information about map format version and map version. The parser is registered as \"autoware_osm_handler\" as lanelet parser","title":"Autoware OSM Parser"},{"location":"map/lanelet2_extension/#projection","text":"","title":"Projection"},{"location":"map/lanelet2_extension/#mgrs-projector","text":"MGRS projector projects latitude longitude into MGRS Coordinates.","title":"MGRS Projector"},{"location":"map/lanelet2_extension/#regulatory-elements","text":"","title":"Regulatory Elements"},{"location":"map/lanelet2_extension/#autoware-traffic-light","text":"Autoware Traffic Light class allows you to retrieve information about traffic lights. Autoware Traffic Light class contains following members: traffic light shape light bulbs information of traffic lights stopline associated to traffic light","title":"Autoware Traffic Light"},{"location":"map/lanelet2_extension/#utility","text":"","title":"Utility"},{"location":"map/lanelet2_extension/#message-conversion","text":"This contains functions to convert lanelet map objects into ROS messages. Currently it contains following conversions: lanelet::LaneletMapPtr to/from autoware_auto_mapping_msgs::msg::HADMapBin lanelet::Point3d to geometry_msgs::Point lanelet::Point2d to geometry_msgs::Point lanelet::BasicPoint3d to geometry_msgs::Point","title":"Message Conversion"},{"location":"map/lanelet2_extension/#query","text":"This module contains functions to retrieve various information from maps. e.g. crosswalks, trafficlights, stoplines","title":"Query"},{"location":"map/lanelet2_extension/#utilities","text":"This module contains other useful functions related to Lanelet. e.g. matching waypoint with lanelets","title":"Utilities"},{"location":"map/lanelet2_extension/#visualization","text":"Visualization contains functions to convert lanelet objects into visualization marker messages. Currently it contains following conversions: lanelet::Lanelet to Triangle Markers lanelet::LineString to LineStrip Markers TrafficLights to Triangle Markers","title":"Visualization"},{"location":"map/lanelet2_extension/#nodes","text":"","title":"Nodes"},{"location":"map/lanelet2_extension/#lanelet2_extension_sample","text":"Code for this explains how this lanelet2_extension library is used. The executable is not meant to do anything.","title":"lanelet2_extension_sample"},{"location":"map/lanelet2_extension/#autoware_lanelet2_extension","text":"This node checks if an .osm file follows the Autoware version of Lanelet2 format. You can check by running: ros2 run lanelet2_extension autoware_lanelet2_validation _map_file: = <path/to/map.osm>","title":"autoware_lanelet2_extension"},{"location":"map/lanelet2_extension/docs/extra_lanelet_subtypes/","text":"Extra Lanelet Subtypes # Roadside Lane # The subtypes for this lanelet classify the outer lanes adjacent to the driving lane.Since the list of lanelet subtypes defined in this link cannot represent the shoulder lane and pedestrian lane described below, two new subtypes are defined.When parking on the street, it is necessary to distinguish between a shoulder lane which can be used by vehicles, and a pedestrian lane which can be used by pedestrians and bicycles.If you park in a shoulder lane, you can use the entire lane for temporary parking, but if you park in a pedestrian lane, you must leave a space of at least 75cm. Road shoulder subtype # refers: lanelet with subtype attribute. Subtype explains what the type of roadside it represents. If there is an area outside of this roadside lane that is open to traffic, such as a sidewalk or bike lane, select the road_shoulder subtype. Sample road shoulder in .osm format is shown below: <relation id= \"120700\" > <member type= \"way\" role= \"left\" ref= \"34577\" /> <member type= \"way\" role= \"right\" ref= \"120694\" /> <tag k= \"type\" v= \"lanelet\" /> <tag k= \"subtype\" v= \"road_shoulder\" /> <tag k= \"speed_limit\" v= \"10\" /> <tag k= \"location\" v= \"urban\" /> <tag k= \"one_way\" v= \"yes\" /> </relation> Pedestrian lane subtype # refers: lanelet with subtype attribute. Subtype explains what the type of roadside it represents. If there are no passable areas outside of this roadside lane, select the pedestrian_lane subtype. Sample pedestrian lane in .osm format is shown below: <relation id= \"120700\" > <member type= \"way\" role= \"left\" ref= \"34577\" /> <member type= \"way\" role= \"right\" ref= \"120694\" /> <tag k= \"type\" v= \"lanelet\" /> <tag k= \"subtype\" v= \"pedestrian_lane\" /> <tag k= \"speed_limit\" v= \"10\" /> <tag k= \"location\" v= \"urban\" /> <tag k= \"one_way\" v= \"yes\" /> </relation>","title":"Extra Lanelet Subtypes"},{"location":"map/lanelet2_extension/docs/extra_lanelet_subtypes/#extra-lanelet-subtypes","text":"","title":"Extra Lanelet Subtypes"},{"location":"map/lanelet2_extension/docs/extra_lanelet_subtypes/#roadside-lane","text":"The subtypes for this lanelet classify the outer lanes adjacent to the driving lane.Since the list of lanelet subtypes defined in this link cannot represent the shoulder lane and pedestrian lane described below, two new subtypes are defined.When parking on the street, it is necessary to distinguish between a shoulder lane which can be used by vehicles, and a pedestrian lane which can be used by pedestrians and bicycles.If you park in a shoulder lane, you can use the entire lane for temporary parking, but if you park in a pedestrian lane, you must leave a space of at least 75cm.","title":"Roadside Lane"},{"location":"map/lanelet2_extension/docs/extra_lanelet_subtypes/#road-shoulder-subtype","text":"refers: lanelet with subtype attribute. Subtype explains what the type of roadside it represents. If there is an area outside of this roadside lane that is open to traffic, such as a sidewalk or bike lane, select the road_shoulder subtype. Sample road shoulder in .osm format is shown below: <relation id= \"120700\" > <member type= \"way\" role= \"left\" ref= \"34577\" /> <member type= \"way\" role= \"right\" ref= \"120694\" /> <tag k= \"type\" v= \"lanelet\" /> <tag k= \"subtype\" v= \"road_shoulder\" /> <tag k= \"speed_limit\" v= \"10\" /> <tag k= \"location\" v= \"urban\" /> <tag k= \"one_way\" v= \"yes\" /> </relation>","title":"Road shoulder subtype"},{"location":"map/lanelet2_extension/docs/extra_lanelet_subtypes/#pedestrian-lane-subtype","text":"refers: lanelet with subtype attribute. Subtype explains what the type of roadside it represents. If there are no passable areas outside of this roadside lane, select the pedestrian_lane subtype. Sample pedestrian lane in .osm format is shown below: <relation id= \"120700\" > <member type= \"way\" role= \"left\" ref= \"34577\" /> <member type= \"way\" role= \"right\" ref= \"120694\" /> <tag k= \"type\" v= \"lanelet\" /> <tag k= \"subtype\" v= \"pedestrian_lane\" /> <tag k= \"speed_limit\" v= \"10\" /> <tag k= \"location\" v= \"urban\" /> <tag k= \"one_way\" v= \"yes\" /> </relation>","title":"Pedestrian lane subtype"},{"location":"map/lanelet2_extension/docs/extra_regulatory_elements/","text":"Extra Regulatory Elements # Detection Area # This regulatory element specifies region of interest which vehicle must pay attention whenever it is driving along the associated lanelet. When there are any obstacle in the detection area, vehicle must stop at specified stopline. refers: refers to detection area polygon. There could be multiple detection areas registered to a single regulatory element. refline: refers to stop line of the detection area Sample detection area in .osm format is shown below: <node id= 1 version= '1' lat= '49.00541994701' lon= '8.41565013855' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 2 version= '1' lat= '49.00542091657' lon= '8.4156469497' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 3 version= '1' lat= '49.00542180052' lon= '8.41564400223' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 4 version= '1' lat= '49.00541994701' lon= '8.41564400223' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 5 version= '1' lat= '49.00542180052' lon= '8.41564400223' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 6 version= '1' lat= '49.00541994701' lon= '8.41564400223' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <way id= 11 version= '1' > <nd ref= 1 /> <nd ref= 2 /> <nd ref= 3 /> <nd ref= 4 /> <nd ref= 1 /> <tag k= 'type' v= \u2019detection_area\u2019 /> <tag k= 'area' v= \u2019yes\u2019 /> </way> <way id= 12 version= \"1\" > <nd ref= 5 /> <nd ref= 6 /> <tag k= 'type' v= stop_line\u2019 /> </way> <relation id= \"13\" > <tag k= \"type\" v= \"regulatory_element\" /> <tag k= \"subtype\" v= \"detection_area\" /> <member type= \"way\" ref= \"11\" role= \"refers\" /> <member type= \"way\" ref= \"12\" role= \"ref_line\" /> </relation> Road Marking # This regulatory element specifies related road markings to a lanelet as shown below. * Note that the stopline in the image is for stoplines that are for reference, and normal stoplines should be expressed using TrafficSign regulatory element. refers: linestring with type attribute. Type explains what road marking it represents (e.g. stopline).","title":"Extra Regulatory Elements"},{"location":"map/lanelet2_extension/docs/extra_regulatory_elements/#extra-regulatory-elements","text":"","title":"Extra Regulatory Elements"},{"location":"map/lanelet2_extension/docs/extra_regulatory_elements/#detection-area","text":"This regulatory element specifies region of interest which vehicle must pay attention whenever it is driving along the associated lanelet. When there are any obstacle in the detection area, vehicle must stop at specified stopline. refers: refers to detection area polygon. There could be multiple detection areas registered to a single regulatory element. refline: refers to stop line of the detection area Sample detection area in .osm format is shown below: <node id= 1 version= '1' lat= '49.00541994701' lon= '8.41565013855' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 2 version= '1' lat= '49.00542091657' lon= '8.4156469497' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 3 version= '1' lat= '49.00542180052' lon= '8.41564400223' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 4 version= '1' lat= '49.00541994701' lon= '8.41564400223' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 5 version= '1' lat= '49.00542180052' lon= '8.41564400223' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <node id= 6 version= '1' lat= '49.00541994701' lon= '8.41564400223' > <tag k= \u2019ele\u2019 v= \u20190\u2019/ > </node> <way id= 11 version= '1' > <nd ref= 1 /> <nd ref= 2 /> <nd ref= 3 /> <nd ref= 4 /> <nd ref= 1 /> <tag k= 'type' v= \u2019detection_area\u2019 /> <tag k= 'area' v= \u2019yes\u2019 /> </way> <way id= 12 version= \"1\" > <nd ref= 5 /> <nd ref= 6 /> <tag k= 'type' v= stop_line\u2019 /> </way> <relation id= \"13\" > <tag k= \"type\" v= \"regulatory_element\" /> <tag k= \"subtype\" v= \"detection_area\" /> <member type= \"way\" ref= \"11\" role= \"refers\" /> <member type= \"way\" ref= \"12\" role= \"ref_line\" /> </relation>","title":"Detection Area"},{"location":"map/lanelet2_extension/docs/extra_regulatory_elements/#road-marking","text":"This regulatory element specifies related road markings to a lanelet as shown below. * Note that the stopline in the image is for stoplines that are for reference, and normal stoplines should be expressed using TrafficSign regulatory element. refers: linestring with type attribute. Type explains what road marking it represents (e.g. stopline).","title":"Road Marking"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/","text":"Modifying Lanelet2 format for Autoware # Overview # About the basics of the default format, please refer to main Lanelet2 repository . (see here about primitives) In addition to default Lanelet2 Format, users should add following mandatory/optional tags to their osm lanelet files as explained in reset of this document. Users may use autoware_lanelet2_validation node to check if their maps are valid. The following is the extra format added for Autoware: extra regulatory elements Detection Area Road Marking extra lanelet subtype Roadside Lane Mandatory Tags # Elevation Tags # Elevation(\"ele\") information for points( node ) is optional in default Lanelet2 format. However, some of Autoware packages(e.g. trafficlight_recognizer) need elevation to be included in HD map. Therefore, users must make sure that all points in their osm maps contain elevation tags. Here is an example osm syntax for node object. <node id= '1' visible= 'true' version= '1' lat= '49.00501435943' lon= '8.41687458512' > <tag k= 'ele' v= '3.0' /> <!-- this tag is mandatory for Autoware!! --> </node> TrafficLights # Default Lanelet2 format uses LineString( way ) or Polygon class to represent the shape of a traffic light. For Autoware, traffic light objects must be represented only by LineString to avoid confusion, where start point is at bottom left edge and end point is at bottom right edge. Also, \"height\" tag must be added in order to represent the size in vertical direction (not the position). The Following image illustrates how LineString is used to represent shape of Traffic Light in Autoware. Here is an example osm syntax for traffic light object. <way id= '13' visible= 'true' version= '1' > <nd ref= '6' /> <nd ref= '5' /> <tag k= 'type' v= 'traffic_light' /> <tag k= 'subtype' v= 'red_yellow_green' /> <tag k= 'height' v= '0.5' /> <!-- this tag is mandatory for Autoware!! --> </way> Turn Directions # Users must add \"turn_direction\" tags to lanelets within intersections to indicate vehicle's turning direction. You do not need this tags for lanelets that are not in intersections. If you do not have this tag, Autoware will not be able to light up turning indicators. This tags only take following values: left right straight Following image illustrates how lanelets should be tagged. Here is an example of osm syntax for lanelets in intersections. <relation id= '1' visible= 'true' version= '1' > <member type= 'way' ref= '2' role= 'left' /> <member type= 'way' ref= '3' role= 'right' /> <member type= 'relation' ref= '4' role= 'regulatory_element' /> <tag k= 'location' v= 'urban' /> <tag k= 'one_way' v= 'yes' /> <tag k= 'subtype' v= 'road' /> <tag k= 'type' v= 'lanelet' /> <tag k= 'turn_direction' v= 'left' /> <!-- this tag is mandatory for lanelets at intersections!! --> </relation> Optional Taggings # Following tags are optional tags that you may want to add depending on how you want to use your map in Autoware. Meta Info # Users may add the MetaInfo element to their OSM file to indicate format version and map version of their OSM file. This information is not meant to influence Autoware vehicle's behavior, but is published as ROS message so that developers could know which map was used from ROSBAG log files. MetaInfo elements exists in the same hierarchy with node , way , and relation elements, otherwise JOSM wouldn't be able to load the file correctly. Here is an example of MetaInfo in osm file: <?xml version='1.0' encoding='UTF-8'?> <osm version= '0.6' generator= 'JOSM' > <MetaInfo format_version= '1.0' map_version= '1.0' /> <node> ... </node> <way> ... </way> <relation> ... </relation> </osm> Local Coordinate Expression # Sometimes users might want to create Lanelet2 maps that are not georeferenced. In such a case, users may use \"local_x\", \"local_y\" taggings to express local positions instead of latitude and longitude. Autoware Osm Parser will overwrite x,y positions with these tags when they are present. For z values, use \"ele\" tags as default Lanelet2 Format. You would still need to fill in lat and lon attributes so that parser does not crush, but their values could be anything. Here is example node element in osm with \"local_x\", \"local_y\" taggings: <!-- lat/lon attributes are required, but their values can be anything --> <node id= '40648' visible= 'true' version= '1' lat= '0' lon= '0' > <tag k= 'local_x' v= 2.54'/ > <tag k= 'local_y' v= 4.38'/ > <tag k= 'ele' v= '3.0' /> </node> Light Bulbs in Traffic Lights # Default Lanelet format can only express shape (base + height) of traffic lights. However, region_tlr node in Autoware uses positions of each light bulbs to recognize color of traffic light. If users may wish to use this node, \"light_bulbs\"( way ) element must be registered to traffic_light regulatory_element object define position and color of each light bulb in traffic lights. If you are using other trafficlight_recognizer nodes(e.g. tlr_mxnet), which only uses bounding box of traffic light, then you do not need to add this object. \"light_bulbs\" object is defined using LineString( way ), and each node of line string is placed at the center of each light bulb. Also, each node should have \"color\" and optionally \"arrow\" tags to describe its type. Also, \"traffic_light_id\" tag is used to indicate which ID of relevant traffic_light element. \"color\" tag is used to express the color of the light bulb. Currently only three values are used: red yellow green \"arrow\" tag is used to express the direction of the arrow of light bulb: up right left up_right up_left Following image illustrates how \"light_bulbs\" LineString should be created. Here is an example of osm syntax for light_bulb object: <node id= 1 version= '1' lat= '49.00541994701' lon= '8.41565013855' > <tag k= 'ele' v= '5' /> <tag k= 'color' v= 'red' /> </node> <node id= 2 version= '1' lat= '49.00542091657' lon= '8.4156469497' > <tag k= 'ele' v= '5' /> <tag k= 'color' v= 'yellow' /> </node> <node id= 3 version= '1' lat= '49.00542180052' lon= '8.41564400223' > <tag k= 'ele' v= '5' /> <tag k= 'color' v= 'green' /> </node> <node id= 3 version= '1' lat= '49.00542180052' lon= '8.41564400223' > <tag k= 'ele' v= '4.6' /> <tag k= 'color' v= 'green' /> <tag k= arrow v= 'right' /> </node> <way id= 11 version= '1' > <nd ref= 1 /> <nd ref= 2 /> <nd ref= 3 /> <tag k= 'traffic_light_id' v= '10' /> <!-- id of linestring with type=\"traffic_light\" --> <tag k= 'type' v= 'light_bulbs' /> </way> After creating \"light_bulbs\" elements, you have to register them to traffic_light regulatory element as role \"light_bulbs\". The following illustrates how light_bulbs are registered to traffic_light regulatory elements. <relation id= '8' visible= 'true' version= '1' > <tag k= 'type' v= 'regulatory_element' /> <tag k= 'subtype' v= 'traffic_light' /> <member type= 'way' ref= '9' role= 'ref_line' /> <member type= 'way' ref= '10' role= 'refers' /> <!-- refers to the traffic light line string --> <member type= 'way' ref= '11' role= 'light_bulbs' /> <!-- refers to the light_bulb line string --> </relation>","title":"Modifying Lanelet2 format for Autoware"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#modifying-lanelet2-format-for-autoware","text":"","title":"Modifying Lanelet2 format for Autoware"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#overview","text":"About the basics of the default format, please refer to main Lanelet2 repository . (see here about primitives) In addition to default Lanelet2 Format, users should add following mandatory/optional tags to their osm lanelet files as explained in reset of this document. Users may use autoware_lanelet2_validation node to check if their maps are valid. The following is the extra format added for Autoware: extra regulatory elements Detection Area Road Marking extra lanelet subtype Roadside Lane","title":"Overview"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#mandatory-tags","text":"","title":"Mandatory Tags"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#elevation-tags","text":"Elevation(\"ele\") information for points( node ) is optional in default Lanelet2 format. However, some of Autoware packages(e.g. trafficlight_recognizer) need elevation to be included in HD map. Therefore, users must make sure that all points in their osm maps contain elevation tags. Here is an example osm syntax for node object. <node id= '1' visible= 'true' version= '1' lat= '49.00501435943' lon= '8.41687458512' > <tag k= 'ele' v= '3.0' /> <!-- this tag is mandatory for Autoware!! --> </node>","title":"Elevation Tags"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#trafficlights","text":"Default Lanelet2 format uses LineString( way ) or Polygon class to represent the shape of a traffic light. For Autoware, traffic light objects must be represented only by LineString to avoid confusion, where start point is at bottom left edge and end point is at bottom right edge. Also, \"height\" tag must be added in order to represent the size in vertical direction (not the position). The Following image illustrates how LineString is used to represent shape of Traffic Light in Autoware. Here is an example osm syntax for traffic light object. <way id= '13' visible= 'true' version= '1' > <nd ref= '6' /> <nd ref= '5' /> <tag k= 'type' v= 'traffic_light' /> <tag k= 'subtype' v= 'red_yellow_green' /> <tag k= 'height' v= '0.5' /> <!-- this tag is mandatory for Autoware!! --> </way>","title":"TrafficLights"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#turn-directions","text":"Users must add \"turn_direction\" tags to lanelets within intersections to indicate vehicle's turning direction. You do not need this tags for lanelets that are not in intersections. If you do not have this tag, Autoware will not be able to light up turning indicators. This tags only take following values: left right straight Following image illustrates how lanelets should be tagged. Here is an example of osm syntax for lanelets in intersections. <relation id= '1' visible= 'true' version= '1' > <member type= 'way' ref= '2' role= 'left' /> <member type= 'way' ref= '3' role= 'right' /> <member type= 'relation' ref= '4' role= 'regulatory_element' /> <tag k= 'location' v= 'urban' /> <tag k= 'one_way' v= 'yes' /> <tag k= 'subtype' v= 'road' /> <tag k= 'type' v= 'lanelet' /> <tag k= 'turn_direction' v= 'left' /> <!-- this tag is mandatory for lanelets at intersections!! --> </relation>","title":"Turn Directions"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#optional-taggings","text":"Following tags are optional tags that you may want to add depending on how you want to use your map in Autoware.","title":"Optional Taggings"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#meta-info","text":"Users may add the MetaInfo element to their OSM file to indicate format version and map version of their OSM file. This information is not meant to influence Autoware vehicle's behavior, but is published as ROS message so that developers could know which map was used from ROSBAG log files. MetaInfo elements exists in the same hierarchy with node , way , and relation elements, otherwise JOSM wouldn't be able to load the file correctly. Here is an example of MetaInfo in osm file: <?xml version='1.0' encoding='UTF-8'?> <osm version= '0.6' generator= 'JOSM' > <MetaInfo format_version= '1.0' map_version= '1.0' /> <node> ... </node> <way> ... </way> <relation> ... </relation> </osm>","title":"Meta Info"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#local-coordinate-expression","text":"Sometimes users might want to create Lanelet2 maps that are not georeferenced. In such a case, users may use \"local_x\", \"local_y\" taggings to express local positions instead of latitude and longitude. Autoware Osm Parser will overwrite x,y positions with these tags when they are present. For z values, use \"ele\" tags as default Lanelet2 Format. You would still need to fill in lat and lon attributes so that parser does not crush, but their values could be anything. Here is example node element in osm with \"local_x\", \"local_y\" taggings: <!-- lat/lon attributes are required, but their values can be anything --> <node id= '40648' visible= 'true' version= '1' lat= '0' lon= '0' > <tag k= 'local_x' v= 2.54'/ > <tag k= 'local_y' v= 4.38'/ > <tag k= 'ele' v= '3.0' /> </node>","title":"Local Coordinate Expression"},{"location":"map/lanelet2_extension/docs/lanelet2_format_extension/#light-bulbs-in-traffic-lights","text":"Default Lanelet format can only express shape (base + height) of traffic lights. However, region_tlr node in Autoware uses positions of each light bulbs to recognize color of traffic light. If users may wish to use this node, \"light_bulbs\"( way ) element must be registered to traffic_light regulatory_element object define position and color of each light bulb in traffic lights. If you are using other trafficlight_recognizer nodes(e.g. tlr_mxnet), which only uses bounding box of traffic light, then you do not need to add this object. \"light_bulbs\" object is defined using LineString( way ), and each node of line string is placed at the center of each light bulb. Also, each node should have \"color\" and optionally \"arrow\" tags to describe its type. Also, \"traffic_light_id\" tag is used to indicate which ID of relevant traffic_light element. \"color\" tag is used to express the color of the light bulb. Currently only three values are used: red yellow green \"arrow\" tag is used to express the direction of the arrow of light bulb: up right left up_right up_left Following image illustrates how \"light_bulbs\" LineString should be created. Here is an example of osm syntax for light_bulb object: <node id= 1 version= '1' lat= '49.00541994701' lon= '8.41565013855' > <tag k= 'ele' v= '5' /> <tag k= 'color' v= 'red' /> </node> <node id= 2 version= '1' lat= '49.00542091657' lon= '8.4156469497' > <tag k= 'ele' v= '5' /> <tag k= 'color' v= 'yellow' /> </node> <node id= 3 version= '1' lat= '49.00542180052' lon= '8.41564400223' > <tag k= 'ele' v= '5' /> <tag k= 'color' v= 'green' /> </node> <node id= 3 version= '1' lat= '49.00542180052' lon= '8.41564400223' > <tag k= 'ele' v= '4.6' /> <tag k= 'color' v= 'green' /> <tag k= arrow v= 'right' /> </node> <way id= 11 version= '1' > <nd ref= 1 /> <nd ref= 2 /> <nd ref= 3 /> <tag k= 'traffic_light_id' v= '10' /> <!-- id of linestring with type=\"traffic_light\" --> <tag k= 'type' v= 'light_bulbs' /> </way> After creating \"light_bulbs\" elements, you have to register them to traffic_light regulatory element as role \"light_bulbs\". The following illustrates how light_bulbs are registered to traffic_light regulatory elements. <relation id= '8' visible= 'true' version= '1' > <tag k= 'type' v= 'regulatory_element' /> <tag k= 'subtype' v= 'traffic_light' /> <member type= 'way' ref= '9' role= 'ref_line' /> <member type= 'way' ref= '10' role= 'refers' /> <!-- refers to the traffic light line string --> <member type= 'way' ref= '11' role= 'light_bulbs' /> <!-- refers to the light_bulb line string --> </relation>","title":"Light Bulbs in Traffic Lights"},{"location":"map/map_loader/","text":"map_loader package # This package provides the features of loading various maps. pointcloud_map_loader # Feature # pointcloud_map_loader loads PointCloud file and publishes the map data as sensor_msgs/PointCloud2 message. How to run # ros2 run map_loader pointcloud_map_loader --ros-args -p \"pcd_paths_or_directory:=[path/to/pointcloud1.pcd, path/to/pointcloud2.pcd, ...]\" Published Topics # pointcloud_map (sensor_msgs/PointCloud2) : PointCloud Map lanelet2_map_loader # Feature # lanelet2_map_loader loads Lanelet2 file and publishes the map data as autoware_lanelet2_msgs/MapBin message. The node projects lan/lon coordinates into MGRS coordinates. How to run # ros2 run map_loader lanelet2_map_loader --ros-args -p lanelet2_map_path:=path/to/map.osm Published Topics # ~output/lanelet2_map (autoware_lanelet2_msgs/MapBin) : Binary data of loaded Lanelet2 Map lanelet2_map_visualization # Feature # lanelet2_map_visualization visualizes autoware_lanelet2_msgs/MapBin messages into visualization_msgs/MarkerArray. How to Run # ros2 run map_loader lanelet2_map_visualization Subscribed Topics # ~input/lanelet2_map (autoware_lanelet2_msgs/MapBin) : binary data of Lanelet2 Map Published Topics # ~output/lanelet2_map_marker (visualization_msgs/MarkerArray) : visualization messages for RViz elevation_map_loader # Feature # Generate elevation_map from subscribed pointcloud_map and vector_map and publish it. Save the generated elevation_map locally and load it from next time. The elevation value of each cell is the average value of z of the points of the lowest cluster. Cells with No elevation value can be inpainted using the values of neighboring cells. How to run # ros2 run map_loader elevation_map_loader --ros-args -p param_file_path:=path/to/elevation_map_parameters.yaml -p elevation_map_directory:=path/to/elevation_map_directory -p pointcloud_map_path:=path/to/pointcloud.pcd Subscribed Topics # input/pointcloud_map (sensor_msgs:PointCloud2) : PointCloud Map input/vector_map (autoware_lanelet2_msgs/MapBin) : binary data of Lanelet2 Map Published Topics # output/elevation_map (grid_map_msgs/GridMap) : Elevation Map output/elevation_map_cloud (sensor_msgs:PointCloud2) : Pointcloud generated from the value of Elevation Map Parameter description # ROS parameters # Name Type Description Default value map_layer_name std::string elevation_map layer name elevation param_file_path std::string GridMap parameters config path_default elevation_map_file_path std::string elevation_map file (bag2) path_default map_frame std::string map_frame when loading elevation_map file map use_inpaint bool Whether to inpaint empty cells true inpaint_radius float Radius of a circular neighborhood of each point inpainted that is considered by the algorithm [m] 0.3 use_elevation_map_cloud_publisher bool Whether to publish output/elevation_map_cloud false use_lane_filter bool Whether to filter elevation_map with vector_map false lane_margin float Value of how much to expand the range of vector_map [m] 0.5 lane_height_diff_thresh float Only point clouds in the height range of this value from vector_map are used to generate elevation_map [m] 1.0 lane_filter_voxel_size_x float Voxel size x for calculating point clouds in vector_map [m] 0.04 lane_filter_voxel_size_y float Voxel size y for calculating point clouds in vector_map [m] 0.04 lane_filter_voxel_size_z float Voxel size z for calculating point clouds in vector_map [m] 0.04 GridMap parameters # The parameters are described on config/elevation_map_parameters.yaml . General parameters # Name Type Description Default value pcl_grid_map_extraction/num_processing_threads int Number of threads for processing grid map cells. Filtering of the raw input point cloud is not parallelized. 12 Grid map parameters # See: https://github.com/ANYbotics/grid_map/tree/ros2/grid_map_pcl Resulting grid map parameters. Name Type Description Default value pcl_grid_map_extraction/grid_map/min_num_points_per_cell int Minimum number of points in the point cloud that have to fall within any of the grid map cells. Otherwise the cell elevation will be set to NaN. 3 pcl_grid_map_extraction/grid_map/resolution float Resolution of the grid map. Width and length are computed automatically. 0.3 Point Cloud Pre-processing Parameters # Rigid body transform parameters # Rigid body transform that is applied to the point cloud before computing elevation. Name Type Description Default value pcl_grid_map_extraction/cloud_transform/translation float Translation (xyz) that is applied to the input point cloud before computing elevation. 0.0 pcl_grid_map_extraction/cloud_transform/rotation float Rotation (intrinsic rotation, convention X-Y'-Z'') that is applied to the input point cloud before computing elevation. 0.0 Cluster extraction parameters # Cluster extraction is based on pcl algorithms. See https://pointclouds.org/documentation/tutorials/cluster_extraction.html for more details. Name Type Description Default value pcl_grid_map_extraction/cluster_extraction/cluster_tolerance float Distance between points below which they will still be considered part of one cluster. 0.2 pcl_grid_map_extraction/cluster_extraction/min_num_points int Min number of points that a cluster needs to have (otherwise it will be discarded). 3 pcl_grid_map_extraction/cluster_extraction/max_num_points int Max number of points that a cluster can have (otherwise it will be discarded). 1000000 Outlier removal parameters # See https://pointclouds.org/documentation/tutorials/statistical_outlier.html for more explanation on outlier removal. Name Type Description Default value pcl_grid_map_extraction/outlier_removal/is_remove_outliers float Whether to perform statistical outlier removal. false pcl_grid_map_extraction/outlier_removal/mean_K float Number of neighbours to analyze for estimating statistics of a point. 10 pcl_grid_map_extraction/outlier_removal/stddev_threshold float Number of standard deviations under which points are considered to be inliers. 1.0 Subsampling parameters # See https://pointclouds.org/documentation/tutorials/voxel_grid.html for more explanation on point cloud downsampling. Name Type Description Default value pcl_grid_map_extraction/downsampling/is_downsample_cloud bool Whether to perform downsampling or not. false pcl_grid_map_extraction/downsampling/voxel_size float Voxel sizes (xyz) in meters. 0.02","title":"map_loader package"},{"location":"map/map_loader/#map_loader-package","text":"This package provides the features of loading various maps.","title":"map_loader package"},{"location":"map/map_loader/#pointcloud_map_loader","text":"","title":"pointcloud_map_loader"},{"location":"map/map_loader/#feature","text":"pointcloud_map_loader loads PointCloud file and publishes the map data as sensor_msgs/PointCloud2 message.","title":"Feature"},{"location":"map/map_loader/#how-to-run","text":"ros2 run map_loader pointcloud_map_loader --ros-args -p \"pcd_paths_or_directory:=[path/to/pointcloud1.pcd, path/to/pointcloud2.pcd, ...]\"","title":"How to run"},{"location":"map/map_loader/#published-topics","text":"pointcloud_map (sensor_msgs/PointCloud2) : PointCloud Map","title":"Published Topics"},{"location":"map/map_loader/#lanelet2_map_loader","text":"","title":"lanelet2_map_loader"},{"location":"map/map_loader/#feature_1","text":"lanelet2_map_loader loads Lanelet2 file and publishes the map data as autoware_lanelet2_msgs/MapBin message. The node projects lan/lon coordinates into MGRS coordinates.","title":"Feature"},{"location":"map/map_loader/#how-to-run_1","text":"ros2 run map_loader lanelet2_map_loader --ros-args -p lanelet2_map_path:=path/to/map.osm","title":"How to run"},{"location":"map/map_loader/#published-topics_1","text":"~output/lanelet2_map (autoware_lanelet2_msgs/MapBin) : Binary data of loaded Lanelet2 Map","title":"Published Topics"},{"location":"map/map_loader/#lanelet2_map_visualization","text":"","title":"lanelet2_map_visualization"},{"location":"map/map_loader/#feature_2","text":"lanelet2_map_visualization visualizes autoware_lanelet2_msgs/MapBin messages into visualization_msgs/MarkerArray.","title":"Feature"},{"location":"map/map_loader/#how-to-run_2","text":"ros2 run map_loader lanelet2_map_visualization","title":"How to Run"},{"location":"map/map_loader/#subscribed-topics","text":"~input/lanelet2_map (autoware_lanelet2_msgs/MapBin) : binary data of Lanelet2 Map","title":"Subscribed Topics"},{"location":"map/map_loader/#published-topics_2","text":"~output/lanelet2_map_marker (visualization_msgs/MarkerArray) : visualization messages for RViz","title":"Published Topics"},{"location":"map/map_loader/#elevation_map_loader","text":"","title":"elevation_map_loader"},{"location":"map/map_loader/#feature_3","text":"Generate elevation_map from subscribed pointcloud_map and vector_map and publish it. Save the generated elevation_map locally and load it from next time. The elevation value of each cell is the average value of z of the points of the lowest cluster. Cells with No elevation value can be inpainted using the values of neighboring cells.","title":"Feature"},{"location":"map/map_loader/#how-to-run_3","text":"ros2 run map_loader elevation_map_loader --ros-args -p param_file_path:=path/to/elevation_map_parameters.yaml -p elevation_map_directory:=path/to/elevation_map_directory -p pointcloud_map_path:=path/to/pointcloud.pcd","title":"How to run"},{"location":"map/map_loader/#subscribed-topics_1","text":"input/pointcloud_map (sensor_msgs:PointCloud2) : PointCloud Map input/vector_map (autoware_lanelet2_msgs/MapBin) : binary data of Lanelet2 Map","title":"Subscribed Topics"},{"location":"map/map_loader/#published-topics_3","text":"output/elevation_map (grid_map_msgs/GridMap) : Elevation Map output/elevation_map_cloud (sensor_msgs:PointCloud2) : Pointcloud generated from the value of Elevation Map","title":"Published Topics"},{"location":"map/map_loader/#parameter-description","text":"","title":"Parameter description"},{"location":"map/map_loader/#ros-parameters","text":"Name Type Description Default value map_layer_name std::string elevation_map layer name elevation param_file_path std::string GridMap parameters config path_default elevation_map_file_path std::string elevation_map file (bag2) path_default map_frame std::string map_frame when loading elevation_map file map use_inpaint bool Whether to inpaint empty cells true inpaint_radius float Radius of a circular neighborhood of each point inpainted that is considered by the algorithm [m] 0.3 use_elevation_map_cloud_publisher bool Whether to publish output/elevation_map_cloud false use_lane_filter bool Whether to filter elevation_map with vector_map false lane_margin float Value of how much to expand the range of vector_map [m] 0.5 lane_height_diff_thresh float Only point clouds in the height range of this value from vector_map are used to generate elevation_map [m] 1.0 lane_filter_voxel_size_x float Voxel size x for calculating point clouds in vector_map [m] 0.04 lane_filter_voxel_size_y float Voxel size y for calculating point clouds in vector_map [m] 0.04 lane_filter_voxel_size_z float Voxel size z for calculating point clouds in vector_map [m] 0.04","title":"ROS parameters"},{"location":"map/map_loader/#gridmap-parameters","text":"The parameters are described on config/elevation_map_parameters.yaml .","title":"GridMap parameters"},{"location":"map/map_loader/#general-parameters","text":"Name Type Description Default value pcl_grid_map_extraction/num_processing_threads int Number of threads for processing grid map cells. Filtering of the raw input point cloud is not parallelized. 12","title":"General parameters"},{"location":"map/map_loader/#grid-map-parameters","text":"See: https://github.com/ANYbotics/grid_map/tree/ros2/grid_map_pcl Resulting grid map parameters. Name Type Description Default value pcl_grid_map_extraction/grid_map/min_num_points_per_cell int Minimum number of points in the point cloud that have to fall within any of the grid map cells. Otherwise the cell elevation will be set to NaN. 3 pcl_grid_map_extraction/grid_map/resolution float Resolution of the grid map. Width and length are computed automatically. 0.3","title":"Grid map parameters"},{"location":"map/map_loader/#point-cloud-pre-processing-parameters","text":"","title":"Point Cloud Pre-processing Parameters"},{"location":"map/map_loader/#rigid-body-transform-parameters","text":"Rigid body transform that is applied to the point cloud before computing elevation. Name Type Description Default value pcl_grid_map_extraction/cloud_transform/translation float Translation (xyz) that is applied to the input point cloud before computing elevation. 0.0 pcl_grid_map_extraction/cloud_transform/rotation float Rotation (intrinsic rotation, convention X-Y'-Z'') that is applied to the input point cloud before computing elevation. 0.0","title":"Rigid body transform parameters"},{"location":"map/map_loader/#cluster-extraction-parameters","text":"Cluster extraction is based on pcl algorithms. See https://pointclouds.org/documentation/tutorials/cluster_extraction.html for more details. Name Type Description Default value pcl_grid_map_extraction/cluster_extraction/cluster_tolerance float Distance between points below which they will still be considered part of one cluster. 0.2 pcl_grid_map_extraction/cluster_extraction/min_num_points int Min number of points that a cluster needs to have (otherwise it will be discarded). 3 pcl_grid_map_extraction/cluster_extraction/max_num_points int Max number of points that a cluster can have (otherwise it will be discarded). 1000000","title":"Cluster extraction parameters"},{"location":"map/map_loader/#outlier-removal-parameters","text":"See https://pointclouds.org/documentation/tutorials/statistical_outlier.html for more explanation on outlier removal. Name Type Description Default value pcl_grid_map_extraction/outlier_removal/is_remove_outliers float Whether to perform statistical outlier removal. false pcl_grid_map_extraction/outlier_removal/mean_K float Number of neighbours to analyze for estimating statistics of a point. 10 pcl_grid_map_extraction/outlier_removal/stddev_threshold float Number of standard deviations under which points are considered to be inliers. 1.0","title":"Outlier removal parameters"},{"location":"map/map_loader/#subsampling-parameters","text":"See https://pointclouds.org/documentation/tutorials/voxel_grid.html for more explanation on point cloud downsampling. Name Type Description Default value pcl_grid_map_extraction/downsampling/is_downsample_cloud bool Whether to perform downsampling or not. false pcl_grid_map_extraction/downsampling/voxel_size float Voxel sizes (xyz) in meters. 0.02","title":"Subsampling parameters"},{"location":"map/map_tf_generator/Readme/","text":"map_tf_generator # Purpose # This node broadcasts viewer frames for visualization of pointcloud map in Rviz. The position of viewer frames is the geometric center of input pointclouds. Note that there is no module to need viewer frames and this is used only for visualization. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description /map/pointcloud_map sensor_msgs::msg::PointCloud2 Subscribe pointcloud map to calculate position of viewer frames Output # Name Type Description /tf_static tf2_msgs/msg/TFMessage Broadcast viewer frames Parameters # Node Parameters # None Core Parameters # Name Type Default Value Explanation viewer_frame string viewer Name of viewer frame map_frame string map The parent frame name of viewer frame Assumptions / Known limits # TBD.","title":"map_tf_generator"},{"location":"map/map_tf_generator/Readme/#map_tf_generator","text":"","title":"map_tf_generator"},{"location":"map/map_tf_generator/Readme/#purpose","text":"This node broadcasts viewer frames for visualization of pointcloud map in Rviz. The position of viewer frames is the geometric center of input pointclouds. Note that there is no module to need viewer frames and this is used only for visualization.","title":"Purpose"},{"location":"map/map_tf_generator/Readme/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"map/map_tf_generator/Readme/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"map/map_tf_generator/Readme/#input","text":"Name Type Description /map/pointcloud_map sensor_msgs::msg::PointCloud2 Subscribe pointcloud map to calculate position of viewer frames","title":"Input"},{"location":"map/map_tf_generator/Readme/#output","text":"Name Type Description /tf_static tf2_msgs/msg/TFMessage Broadcast viewer frames","title":"Output"},{"location":"map/map_tf_generator/Readme/#parameters","text":"","title":"Parameters"},{"location":"map/map_tf_generator/Readme/#node-parameters","text":"None","title":"Node Parameters"},{"location":"map/map_tf_generator/Readme/#core-parameters","text":"Name Type Default Value Explanation viewer_frame string viewer Name of viewer frame map_frame string map The parent frame name of viewer frame","title":"Core Parameters"},{"location":"map/map_tf_generator/Readme/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"messages/","text":"autoware_iv_msgs #","title":"autoware_iv_msgs"},{"location":"messages/#autoware_iv_msgs","text":"","title":"autoware_iv_msgs"},{"location":"planning/route_handler/","text":"route handler # route_handler is a library for calculating driving route on the lanelet map.","title":"route handler"},{"location":"planning/route_handler/#route-handler","text":"route_handler is a library for calculating driving route on the lanelet map.","title":"route handler"},{"location":"sensing/geo_pos_conv/","text":"geo_pos_conv # Purpose # The geo_pos_conv is a library to calculate the conversion between x, y positions on the plane rectangular coordinate and latitude/longitude on the earth . Inner-workings / Algorithms # Inputs / Outputs # Parameters # Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # (Optional) Future extensions / Unimplemented parts #","title":"geo_pos_conv"},{"location":"sensing/geo_pos_conv/#geo_pos_conv","text":"","title":"geo_pos_conv"},{"location":"sensing/geo_pos_conv/#purpose","text":"The geo_pos_conv is a library to calculate the conversion between x, y positions on the plane rectangular coordinate and latitude/longitude on the earth .","title":"Purpose"},{"location":"sensing/geo_pos_conv/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/geo_pos_conv/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/geo_pos_conv/#parameters","text":"","title":"Parameters"},{"location":"sensing/geo_pos_conv/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/geo_pos_conv/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/geo_pos_conv/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/geo_pos_conv/#optional-referencesexternal-links","text":"","title":"(Optional) References/External links"},{"location":"sensing/geo_pos_conv/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/gnss_poser/","text":"gnss_poser # Purpose # The gnss_poser is a node that subscribes gnss sensing messages and calculates vehicle pose with covariance. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description ~/input/fix sensor_msgs::msg::NavSatFix gnss status message ~/input/navpvt ublox_msgs::msg::NavPVT position, velocity and time solution (You can see detail description in reference document [1]) Output # Name Type Description ~/output/pose geometry_msgs::msg::PoseStamped vehicle pose calculated from gnss sensing data ~/output/gnss_pose_cov geometry_msgs::msg::PoseWithCovarianceStamped vehicle pose with covariance calculated from gnss sensing data ~/output/gnss_fixed autoware_debug_msgs::msg::BoolStamped gnss fix status Parameters # Core Parameters # Name Type Default Value Description base_frame string \"base_link\" frame d gnss_frame string \"gnss\" frame id gnss_base_frame string \"gnss_base_link\" frame id map_frame string \"map\" frame id use_ublox_receiver bool false flag to use ublox receiver plane_zone int 9 identification number of the plane rectangular coordinate systems (See, reference document [2]) Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # [1] https://github.com/KumarRobotics/ublox.git [2] https://www.gsi.go.jp/LAW/heimencho.html (Optional) Future extensions / Unimplemented parts #","title":"gnss_poser"},{"location":"sensing/gnss_poser/#gnss_poser","text":"","title":"gnss_poser"},{"location":"sensing/gnss_poser/#purpose","text":"The gnss_poser is a node that subscribes gnss sensing messages and calculates vehicle pose with covariance.","title":"Purpose"},{"location":"sensing/gnss_poser/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/gnss_poser/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/gnss_poser/#input","text":"Name Type Description ~/input/fix sensor_msgs::msg::NavSatFix gnss status message ~/input/navpvt ublox_msgs::msg::NavPVT position, velocity and time solution (You can see detail description in reference document [1])","title":"Input"},{"location":"sensing/gnss_poser/#output","text":"Name Type Description ~/output/pose geometry_msgs::msg::PoseStamped vehicle pose calculated from gnss sensing data ~/output/gnss_pose_cov geometry_msgs::msg::PoseWithCovarianceStamped vehicle pose with covariance calculated from gnss sensing data ~/output/gnss_fixed autoware_debug_msgs::msg::BoolStamped gnss fix status","title":"Output"},{"location":"sensing/gnss_poser/#parameters","text":"","title":"Parameters"},{"location":"sensing/gnss_poser/#core-parameters","text":"Name Type Default Value Description base_frame string \"base_link\" frame d gnss_frame string \"gnss\" frame id gnss_base_frame string \"gnss_base_link\" frame id map_frame string \"map\" frame id use_ublox_receiver bool false flag to use ublox receiver plane_zone int 9 identification number of the plane rectangular coordinate systems (See, reference document [2])","title":"Core Parameters"},{"location":"sensing/gnss_poser/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/gnss_poser/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/gnss_poser/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/gnss_poser/#optional-referencesexternal-links","text":"[1] https://github.com/KumarRobotics/ublox.git [2] https://www.gsi.go.jp/LAW/heimencho.html","title":"(Optional) References/External links"},{"location":"sensing/gnss_poser/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/laserscan_to_occupancy_grid_map/","text":"laserscan_to_occupancy_grid_map # Purpose # This package outputs the probability of having an obstacle as occupancy grid map. Inner-workings / Algorithms # The basic idea is to take a 2D laserscan and ray trace it to create a time-series processed occupancy grid map. the node take a laserscan and make an occupancy grid map with one frame. ray trace is done by Bresenham's line algorithm. Optionally, obstacle point clouds and raw point clouds can be received and reflected in the occupancy grid map. The reason is that laserscan only uses the most foreground point in the polar coordinate system, so it throws away a lot of information. As a result, the occupancy grid map is almost an UNKNOWN cell. Therefore, the obstacle point cloud and the raw point cloud are used to reflect what is judged to be the ground and what is judged to be an obstacle in the occupancy grid map. The black and red dots represent raw point clouds, and the red dots represent obstacle point clouds. In other words, the black points are determined as the ground, and the red point cloud is the points determined as obstacles. The gray cells are represented as UNKNOWN cells. Using the previous occupancy grid map, update the existence probability using a binary Bayesian filter (1). Also, the unobserved cells are time-decayed like the system noise of the Kalman filter (2). \\hat{P_{o}} = \\frac{(P_{o} * P_{z})}{(P_{o} * P_{z} + (1 - P_{o}) * \\bar{P_{z}})} \\tag{1} \\hat{P_{o}} = \\frac{(P_{o} + 0.5 * \\frac{1}{ratio})}{(\\frac{1}{ratio} + 1)} \\tag{2} Inputs / Outputs # Input # Name Type Description ~/input/laserscan sensor_msgs::LaserScan laserscan ~/input/obstacle_pointcloud sensor_msgs::PointCloud2 obstacle pointcloud ~/input/raw_pointcloud sensor_msgs::PointCloud2 The overall point cloud used to input the obstacle point cloud Output # Name Type Description ~/output/occupancy_grid_map nav_msgs::OccupancyGrid occupancy grid map Parameters # Node Parameters # Name Type Description map_frame string map frame base_link_frame string base_link frame input_obstacle_pointcloud bool whether to use the optional obstacle point cloud? If this is true, ~/input/obstacle_pointcloud topics will be received. input_obstacle_and_raw_pointcloud bool whether to use the optional obstacle and raw point cloud? If this is true, ~/input/obstacle_pointcloud and ~/input/raw_pointcloud topics will be received. use_height_filter bool whether to height filter for ~/input/obstacle_pointcloud and ~/input/raw_pointcloud ? By default, the height is set to -1~2m. map_length double The length of the map. -100 if it is 50~50[m] map_resolution double The map cell resolution [m] Assumptions / Known limits # In several places we have modified the external code written in BSD3 license. occupancy_grid_map.hpp cost_value.hpp occupancy_grid_map.cpp (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # Bresenham's_line_algorithm https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm https://web.archive.org/web/20080528040104/http://www.research.ibm.com/journal/sj/041/ibmsjIVRIC.pdf (Optional) Future extensions / Unimplemented parts # The update probability of the binary Bayesian filter is currently hard-coded and requires a code change to be modified. Since there is no special support for moving objects, the probability of existence is not increased for fast objects.","title":"laserscan_to_occupancy_grid_map"},{"location":"sensing/laserscan_to_occupancy_grid_map/#laserscan_to_occupancy_grid_map","text":"","title":"laserscan_to_occupancy_grid_map"},{"location":"sensing/laserscan_to_occupancy_grid_map/#purpose","text":"This package outputs the probability of having an obstacle as occupancy grid map.","title":"Purpose"},{"location":"sensing/laserscan_to_occupancy_grid_map/#inner-workings-algorithms","text":"The basic idea is to take a 2D laserscan and ray trace it to create a time-series processed occupancy grid map. the node take a laserscan and make an occupancy grid map with one frame. ray trace is done by Bresenham's line algorithm. Optionally, obstacle point clouds and raw point clouds can be received and reflected in the occupancy grid map. The reason is that laserscan only uses the most foreground point in the polar coordinate system, so it throws away a lot of information. As a result, the occupancy grid map is almost an UNKNOWN cell. Therefore, the obstacle point cloud and the raw point cloud are used to reflect what is judged to be the ground and what is judged to be an obstacle in the occupancy grid map. The black and red dots represent raw point clouds, and the red dots represent obstacle point clouds. In other words, the black points are determined as the ground, and the red point cloud is the points determined as obstacles. The gray cells are represented as UNKNOWN cells. Using the previous occupancy grid map, update the existence probability using a binary Bayesian filter (1). Also, the unobserved cells are time-decayed like the system noise of the Kalman filter (2). \\hat{P_{o}} = \\frac{(P_{o} * P_{z})}{(P_{o} * P_{z} + (1 - P_{o}) * \\bar{P_{z}})} \\tag{1} \\hat{P_{o}} = \\frac{(P_{o} + 0.5 * \\frac{1}{ratio})}{(\\frac{1}{ratio} + 1)} \\tag{2}","title":"Inner-workings / Algorithms"},{"location":"sensing/laserscan_to_occupancy_grid_map/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/laserscan_to_occupancy_grid_map/#input","text":"Name Type Description ~/input/laserscan sensor_msgs::LaserScan laserscan ~/input/obstacle_pointcloud sensor_msgs::PointCloud2 obstacle pointcloud ~/input/raw_pointcloud sensor_msgs::PointCloud2 The overall point cloud used to input the obstacle point cloud","title":"Input"},{"location":"sensing/laserscan_to_occupancy_grid_map/#output","text":"Name Type Description ~/output/occupancy_grid_map nav_msgs::OccupancyGrid occupancy grid map","title":"Output"},{"location":"sensing/laserscan_to_occupancy_grid_map/#parameters","text":"","title":"Parameters"},{"location":"sensing/laserscan_to_occupancy_grid_map/#node-parameters","text":"Name Type Description map_frame string map frame base_link_frame string base_link frame input_obstacle_pointcloud bool whether to use the optional obstacle point cloud? If this is true, ~/input/obstacle_pointcloud topics will be received. input_obstacle_and_raw_pointcloud bool whether to use the optional obstacle and raw point cloud? If this is true, ~/input/obstacle_pointcloud and ~/input/raw_pointcloud topics will be received. use_height_filter bool whether to height filter for ~/input/obstacle_pointcloud and ~/input/raw_pointcloud ? By default, the height is set to -1~2m. map_length double The length of the map. -100 if it is 50~50[m] map_resolution double The map cell resolution [m]","title":"Node Parameters"},{"location":"sensing/laserscan_to_occupancy_grid_map/#assumptions-known-limits","text":"In several places we have modified the external code written in BSD3 license. occupancy_grid_map.hpp cost_value.hpp occupancy_grid_map.cpp","title":"Assumptions / Known limits"},{"location":"sensing/laserscan_to_occupancy_grid_map/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/laserscan_to_occupancy_grid_map/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/laserscan_to_occupancy_grid_map/#optional-referencesexternal-links","text":"Bresenham's_line_algorithm https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm https://web.archive.org/web/20080528040104/http://www.research.ibm.com/journal/sj/041/ibmsjIVRIC.pdf","title":"(Optional) References/External links"},{"location":"sensing/laserscan_to_occupancy_grid_map/#optional-future-extensions-unimplemented-parts","text":"The update probability of the binary Bayesian filter is currently hard-coded and requires a code change to be modified. Since there is no special support for moving objects, the probability of existence is not increased for fast objects.","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/livox/livox_tag_filter/","text":"livox_tag_filter # Purpose # The livox_tag_filter is a node that removes noise from pointcloud by using the following tags: Point property based on spatial position Point property based on intensity Return number Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description ~/input sensor_msgs::msg::PointCloud2 reference points Output # Name Type Description ~/output sensor_msgs::msg::PointCloud2 filtered points Parameters # Node Parameters # Name Type Description ignore_tags vector ignored tags (See the following table) Tag Parameters # Bit Description Options 0~1 Point property based on spatial position 00: Normal 01: High confidence level of the noise 10: Moderate confidence level of the noise 11: Low confidence level of the noise 2~3 Point property based on intensity 00: Normal 01: High confidence level of the noise 10: Moderate confidence level of the noise 11: Reserved 4~5 Return number 00: return 0 01: return 1 10: return 2 11: return 3 6~7 Reserved You can download more detail description about the livox from external link [1]. Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # [1] https://www.livoxtech.com/downloads (Optional) Future extensions / Unimplemented parts #","title":"livox_tag_filter"},{"location":"sensing/livox/livox_tag_filter/#livox_tag_filter","text":"","title":"livox_tag_filter"},{"location":"sensing/livox/livox_tag_filter/#purpose","text":"The livox_tag_filter is a node that removes noise from pointcloud by using the following tags: Point property based on spatial position Point property based on intensity Return number","title":"Purpose"},{"location":"sensing/livox/livox_tag_filter/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/livox/livox_tag_filter/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/livox/livox_tag_filter/#input","text":"Name Type Description ~/input sensor_msgs::msg::PointCloud2 reference points","title":"Input"},{"location":"sensing/livox/livox_tag_filter/#output","text":"Name Type Description ~/output sensor_msgs::msg::PointCloud2 filtered points","title":"Output"},{"location":"sensing/livox/livox_tag_filter/#parameters","text":"","title":"Parameters"},{"location":"sensing/livox/livox_tag_filter/#node-parameters","text":"Name Type Description ignore_tags vector ignored tags (See the following table)","title":"Node Parameters"},{"location":"sensing/livox/livox_tag_filter/#tag-parameters","text":"Bit Description Options 0~1 Point property based on spatial position 00: Normal 01: High confidence level of the noise 10: Moderate confidence level of the noise 11: Low confidence level of the noise 2~3 Point property based on intensity 00: Normal 01: High confidence level of the noise 10: Moderate confidence level of the noise 11: Reserved 4~5 Return number 00: return 0 01: return 1 10: return 2 11: return 3 6~7 Reserved You can download more detail description about the livox from external link [1].","title":"Tag Parameters"},{"location":"sensing/livox/livox_tag_filter/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/livox/livox_tag_filter/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/livox/livox_tag_filter/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/livox/livox_tag_filter/#optional-referencesexternal-links","text":"[1] https://www.livoxtech.com/downloads","title":"(Optional) References/External links"},{"location":"sensing/livox/livox_tag_filter/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/pointcloud_preprocessor/","text":"pointcloud_preprocessor # Purpose # The pointcloud_preprocessor is a package that includes the following filters: removing outlier points cropping concatenating pointclouds correcting distortion downsampling Inner-workings / Algorithms # Detail description of each filter's algorithm is in the following links. Filter Name Description Detail concatenate_data subscribe multiple pointclouds and concatenate them into a pointcloud link crop_box_filter remove points within a given box link distortion_corrector compensate pointcloud distortion caused by ego vehicle's movement during 1 scan link downsample_filter downsampling input pointcloud link outlier_filter remove points caused by hardware problems, rain drops and small insects as a noise link passthrough_filter remove points on the outside of a range in given field (e.g. x, y, z, intensity) link pointcloud_accumulator accumulate pointclouds for a given amount of time link vector_map_filter remove points on the outside of lane by using vector map link Inputs / Outputs # Input # Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points ~/input/indices pcl_msgs::msg::Indices reference indices Output # Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points Parameters # Node Parameters # Name Type Default Value Description input_frame string \" \" input frame id output_frame string \" \" output frame id max_queue_size int 5 max queue size of input/output topics use_indices bool false flag to use pointcloud indices latched_indices bool false flag to latch pointcloud indices approximate_sync bool false flag to use approximate sync option Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # (Optional) Future extensions / Unimplemented parts #","title":"pointcloud_preprocessor"},{"location":"sensing/pointcloud_preprocessor/#pointcloud_preprocessor","text":"","title":"pointcloud_preprocessor"},{"location":"sensing/pointcloud_preprocessor/#purpose","text":"The pointcloud_preprocessor is a package that includes the following filters: removing outlier points cropping concatenating pointclouds correcting distortion downsampling","title":"Purpose"},{"location":"sensing/pointcloud_preprocessor/#inner-workings-algorithms","text":"Detail description of each filter's algorithm is in the following links. Filter Name Description Detail concatenate_data subscribe multiple pointclouds and concatenate them into a pointcloud link crop_box_filter remove points within a given box link distortion_corrector compensate pointcloud distortion caused by ego vehicle's movement during 1 scan link downsample_filter downsampling input pointcloud link outlier_filter remove points caused by hardware problems, rain drops and small insects as a noise link passthrough_filter remove points on the outside of a range in given field (e.g. x, y, z, intensity) link pointcloud_accumulator accumulate pointclouds for a given amount of time link vector_map_filter remove points on the outside of lane by using vector map link","title":"Inner-workings / Algorithms"},{"location":"sensing/pointcloud_preprocessor/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/pointcloud_preprocessor/#input","text":"Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points ~/input/indices pcl_msgs::msg::Indices reference indices","title":"Input"},{"location":"sensing/pointcloud_preprocessor/#output","text":"Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points","title":"Output"},{"location":"sensing/pointcloud_preprocessor/#parameters","text":"","title":"Parameters"},{"location":"sensing/pointcloud_preprocessor/#node-parameters","text":"Name Type Default Value Description input_frame string \" \" input frame id output_frame string \" \" output frame id max_queue_size int 5 max queue size of input/output topics use_indices bool false flag to use pointcloud indices latched_indices bool false flag to latch pointcloud indices approximate_sync bool false flag to use approximate sync option","title":"Node Parameters"},{"location":"sensing/pointcloud_preprocessor/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/pointcloud_preprocessor/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/pointcloud_preprocessor/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/pointcloud_preprocessor/#optional-referencesexternal-links","text":"","title":"(Optional) References/External links"},{"location":"sensing/pointcloud_preprocessor/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/","text":"concatenate_data # Purpose # The concatenate_data is a node that concatenates multiple pointclouds acquired by multiple LiDARs into a pointcloud. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description ~/input/points sensor_msgs::msg::Pointcloud2 reference points ~/input/twist autoware_auto_vehicle_msgs::msg::VelocityReport vehicle velocity Output # Name Type Description ~/output/points sensor_msgs::msg::Pointcloud2 filtered points Parameters # Name Type Default Value Description input_frame string \" \" input frame id output_frame string \" \" output frame id max_queue_size int 5 max queue size of input/output topics Core Parameters # Name Type Default Value Description timeout_sec double 0.1 tolerance of time to publish next pointcloud [s] When this time limit is exceeded, the filter concatenates and publishes pointcloud, even if not all the point clouds are subscribed. Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # (Optional) Future extensions / Unimplemented parts #","title":"concatenate_data"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#concatenate_data","text":"","title":"concatenate_data"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#purpose","text":"The concatenate_data is a node that concatenates multiple pointclouds acquired by multiple LiDARs into a pointcloud.","title":"Purpose"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#input","text":"Name Type Description ~/input/points sensor_msgs::msg::Pointcloud2 reference points ~/input/twist autoware_auto_vehicle_msgs::msg::VelocityReport vehicle velocity","title":"Input"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#output","text":"Name Type Description ~/output/points sensor_msgs::msg::Pointcloud2 filtered points","title":"Output"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#parameters","text":"Name Type Default Value Description input_frame string \" \" input frame id output_frame string \" \" output frame id max_queue_size int 5 max queue size of input/output topics","title":"Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#core-parameters","text":"Name Type Default Value Description timeout_sec double 0.1 tolerance of time to publish next pointcloud [s] When this time limit is exceeded, the filter concatenates and publishes pointcloud, even if not all the point clouds are subscribed.","title":"Core Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#optional-referencesexternal-links","text":"","title":"(Optional) References/External links"},{"location":"sensing/pointcloud_preprocessor/docs/concatenate-data/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/","text":"box_crop_filter # Purpose # The box_crop_filter is a node that removes points with in a given box region. This filter is used to remove the points that hit the vehicle itself. Inner-workings / Algorithms # Inputs / Outputs # Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points Output # Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points Parameters # Core Parameters # Name Type Default Value Description min_x double -1.0 x-coordinate minimum value for crop range max_x double 1.0 x-coordinate maximum value for crop range min_y double -1.0 y-coordinate minimum value for crop range max_y double 1.0 y-coordinate maximum value for crop range min_z double -1.0 z-coordinate minimum value for crop range max_z double 1.0 z-coordinate maximum value for crop range Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # (Optional) Future extensions / Unimplemented parts #","title":"box_crop_filter"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#box_crop_filter","text":"","title":"box_crop_filter"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#purpose","text":"The box_crop_filter is a node that removes points with in a given box region. This filter is used to remove the points that hit the vehicle itself.","title":"Purpose"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#inputs-outputs","text":"Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points","title":"Inputs / Outputs"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#output","text":"Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points","title":"Output"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#parameters","text":"","title":"Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#core-parameters","text":"Name Type Default Value Description min_x double -1.0 x-coordinate minimum value for crop range max_x double 1.0 x-coordinate maximum value for crop range min_y double -1.0 y-coordinate minimum value for crop range max_y double 1.0 y-coordinate maximum value for crop range min_z double -1.0 z-coordinate minimum value for crop range max_z double 1.0 z-coordinate maximum value for crop range","title":"Core Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#optional-referencesexternal-links","text":"","title":"(Optional) References/External links"},{"location":"sensing/pointcloud_preprocessor/docs/crop-box-filter/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/","text":"distortion_corrector # Purpose # The distortion_corrector is a node that compensates pointcloud distortion caused by ego vehicle's movement during 1 scan. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points ~/input/velocity_report autoware_auto_vehicle_msgs::msg::VelocityReport vehicle velocity Output # Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points Parameters # Core Parameters # Name Type Default Value Description timestamp_field_name string \"time_stamp\" time stamp field name Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # (Optional) Future extensions / Unimplemented parts #","title":"distortion_corrector"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#distortion_corrector","text":"","title":"distortion_corrector"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#purpose","text":"The distortion_corrector is a node that compensates pointcloud distortion caused by ego vehicle's movement during 1 scan.","title":"Purpose"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#input","text":"Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points ~/input/velocity_report autoware_auto_vehicle_msgs::msg::VelocityReport vehicle velocity","title":"Input"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#output","text":"Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points","title":"Output"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#parameters","text":"","title":"Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#core-parameters","text":"Name Type Default Value Description timestamp_field_name string \"time_stamp\" time stamp field name","title":"Core Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#optional-referencesexternal-links","text":"","title":"(Optional) References/External links"},{"location":"sensing/pointcloud_preprocessor/docs/distortion-corrector/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/","text":"downsample_filter # Purpose # The downsample_filter is a node that reduces the number of points. Inner-workings / Algorithms # Approximate Downsample Filter # WIP Random Downsample Filter # WIP Voxel Grid Downsample Filter # WIP Inputs / Outputs # Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points Output # Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points Parameters # Node Parameters # Name Type Default Value Description voxel_size_x double 0.3 voxel size x [m] voxel_size_y double 0.3 voxel size y [m] voxel_size_z double 0.1 voxel size z [m] sample_num int 1500 number of indices to be sampled Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # (Optional) Future extensions / Unimplemented parts #","title":"downsample_filter"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#downsample_filter","text":"","title":"downsample_filter"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#purpose","text":"The downsample_filter is a node that reduces the number of points.","title":"Purpose"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#approximate-downsample-filter","text":"WIP","title":"Approximate Downsample Filter"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#random-downsample-filter","text":"WIP","title":"Random Downsample Filter"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#voxel-grid-downsample-filter","text":"WIP","title":"Voxel Grid Downsample Filter"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#inputs-outputs","text":"Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points","title":"Inputs / Outputs"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#output","text":"Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points","title":"Output"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#parameters","text":"","title":"Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#node-parameters","text":"Name Type Default Value Description voxel_size_x double 0.3 voxel size x [m] voxel_size_y double 0.3 voxel size y [m] voxel_size_z double 0.1 voxel size z [m] sample_num int 1500 number of indices to be sampled","title":"Node Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#optional-referencesexternal-links","text":"","title":"(Optional) References/External links"},{"location":"sensing/pointcloud_preprocessor/docs/downsample-filter/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/","text":"outlier_filter # Purpose # This node is an outlier filter based on a occupancy grid map. Depending on the implementation of occupancy grid map, it can be called an outlier filter in time series, since the occupancy grid map expresses the occupancy probabilities in time series. Inner-workings / Algorithms # Dual Return Outlier Filter # WIP Occupancy GridMap Outlier Filter # Use the occupancy grid map to separate point clouds into those with low occupancy probability and those with high occupancy probability. The point clouds that belong to the low occupancy probability are not necessarily outliers. In particular, the top of the moving object tends to belong to the low occupancy probability. Therefore, if use_radius_search_2d_filter is true, then apply an radius search 2d outlier filter to the point cloud that is determined to have a low occupancy probability. For each low occupancy probability point, determine the outlier from the radius ( radius_search_2d_filter/search_radius ) and the number of point clouds. In this case, the point cloud to be referenced is not only low occupancy probability points, but all point cloud including high occupancy probability points. The number of point clouds can be multiplied by radius_search_2d_filter/min_points_and_distance_ratio and distance from base link. However, the minimum and maximum number of point clouds is limited. The following video is a sample. Yellow points are high occupancy probability, green points are low occupancy probability which is not an outlier, and red points are outliers. At around 0:15 and 1:16 in the first video, a bird crosses the road, but it is considered as an outlier. movie1 movie2 Radius Search 2d Outlier Filter [1] # WIP Ring Outlier Filter # WIP Voxel Grid Outlier Filter # WIP Inputs / Outputs # Input # Name Type Description ~/input/pointcloud sensor_msgs/PointCloud2 Obstacle point cloud with ground removed. ~/input/occupancy_grid_map nav_msgs/OccupancyGrid A map in which the probability of the presence of an obstacle is occupancy probability map Output # Name Type Description ~/output/pointcloud sensor_msgs/PointCloud2 Point cloud with outliers removed. trajectory ~/output/debug/outlier/pointcloud sensor_msgs/PointCloud2 Point clouds removed as outliers. ~/output/debug/low_confidence/pointcloud sensor_msgs/PointCloud2 Point clouds that had a low probability of occupancy in the occupancy grid map. However, it is not considered as an outlier. ~/output/debug/high_confidence/pointcloud sensor_msgs/PointCloud2 Point clouds that had a high probability of occupancy in the occupancy grid map. trajectory Parameters # Name Type Description map_frame string map frame id base_link_frame string base link frame id cost_threshold int Cost threshold of occupancy grid map (0~100). 100 means 100% probability that there is an obstacle, close to 50 means that it is indistinguishable whether it is an obstacle or free space, 0 means that there is no obstacle. enable_debugger bool Whether to output the point cloud for debugging. use_radius_search_2d_filter bool Whether or not to apply density-based outlier filters to objects that are judged to have low probability of occupancy on the occupancy grid map. radius_search_2d_filter/search_radius float Radius when calculating the density radius_search_2d_filter/min_points_and_distance_ratio float Threshold value of the number of point clouds per radius when the distance from baselink is 1m, because the number of point clouds varies with the distance from baselink. radius_search_2d_filter/min_points int Minimum number of point clouds per radius radius_search_2d_filter/max_points int Maximum number of point clouds per radius Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # [1] https://pcl.readthedocs.io/projects/tutorials/en/latest/remove_outliers.html (Optional) Future extensions / Unimplemented parts #","title":"outlier_filter"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#outlier_filter","text":"","title":"outlier_filter"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#purpose","text":"This node is an outlier filter based on a occupancy grid map. Depending on the implementation of occupancy grid map, it can be called an outlier filter in time series, since the occupancy grid map expresses the occupancy probabilities in time series.","title":"Purpose"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#dual-return-outlier-filter","text":"WIP","title":"Dual Return Outlier Filter"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#occupancy-gridmap-outlier-filter","text":"Use the occupancy grid map to separate point clouds into those with low occupancy probability and those with high occupancy probability. The point clouds that belong to the low occupancy probability are not necessarily outliers. In particular, the top of the moving object tends to belong to the low occupancy probability. Therefore, if use_radius_search_2d_filter is true, then apply an radius search 2d outlier filter to the point cloud that is determined to have a low occupancy probability. For each low occupancy probability point, determine the outlier from the radius ( radius_search_2d_filter/search_radius ) and the number of point clouds. In this case, the point cloud to be referenced is not only low occupancy probability points, but all point cloud including high occupancy probability points. The number of point clouds can be multiplied by radius_search_2d_filter/min_points_and_distance_ratio and distance from base link. However, the minimum and maximum number of point clouds is limited. The following video is a sample. Yellow points are high occupancy probability, green points are low occupancy probability which is not an outlier, and red points are outliers. At around 0:15 and 1:16 in the first video, a bird crosses the road, but it is considered as an outlier. movie1 movie2","title":"Occupancy GridMap Outlier Filter"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#radius-search-2d-outlier-filter-1","text":"WIP","title":"Radius Search 2d Outlier Filter [1]"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#ring-outlier-filter","text":"WIP","title":"Ring Outlier Filter"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#voxel-grid-outlier-filter","text":"WIP","title":"Voxel Grid Outlier Filter"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#input","text":"Name Type Description ~/input/pointcloud sensor_msgs/PointCloud2 Obstacle point cloud with ground removed. ~/input/occupancy_grid_map nav_msgs/OccupancyGrid A map in which the probability of the presence of an obstacle is occupancy probability map","title":"Input"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#output","text":"Name Type Description ~/output/pointcloud sensor_msgs/PointCloud2 Point cloud with outliers removed. trajectory ~/output/debug/outlier/pointcloud sensor_msgs/PointCloud2 Point clouds removed as outliers. ~/output/debug/low_confidence/pointcloud sensor_msgs/PointCloud2 Point clouds that had a low probability of occupancy in the occupancy grid map. However, it is not considered as an outlier. ~/output/debug/high_confidence/pointcloud sensor_msgs/PointCloud2 Point clouds that had a high probability of occupancy in the occupancy grid map. trajectory","title":"Output"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#parameters","text":"Name Type Description map_frame string map frame id base_link_frame string base link frame id cost_threshold int Cost threshold of occupancy grid map (0~100). 100 means 100% probability that there is an obstacle, close to 50 means that it is indistinguishable whether it is an obstacle or free space, 0 means that there is no obstacle. enable_debugger bool Whether to output the point cloud for debugging. use_radius_search_2d_filter bool Whether or not to apply density-based outlier filters to objects that are judged to have low probability of occupancy on the occupancy grid map. radius_search_2d_filter/search_radius float Radius when calculating the density radius_search_2d_filter/min_points_and_distance_ratio float Threshold value of the number of point clouds per radius when the distance from baselink is 1m, because the number of point clouds varies with the distance from baselink. radius_search_2d_filter/min_points int Minimum number of point clouds per radius radius_search_2d_filter/max_points int Maximum number of point clouds per radius","title":"Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#optional-referencesexternal-links","text":"[1] https://pcl.readthedocs.io/projects/tutorials/en/latest/remove_outliers.html","title":"(Optional) References/External links"},{"location":"sensing/pointcloud_preprocessor/docs/outlier-filter/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/","text":"passthrough_filter # Purpose # The passthrough_filter is a node that removes points on the outside of a range in a given field (e.g. x, y, z, intensity, ring, etc). Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points ~/input/indices pcl_msgs::msg::Indices reference indices Output # Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points Parameters # Core Parameters # Name Type Default Value Description filter_limit_min int 0 minimum allowed field value filter_limit_max int 127 maximum allowed field value filter_field_name string \"ring\" filtering field name keep_organized bool false flag to keep indices structure filter_limit_negative bool false flag to return whether the data is inside limit or not Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # (Optional) Future extensions / Unimplemented parts #","title":"passthrough_filter"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#passthrough_filter","text":"","title":"passthrough_filter"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#purpose","text":"The passthrough_filter is a node that removes points on the outside of a range in a given field (e.g. x, y, z, intensity, ring, etc).","title":"Purpose"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#input","text":"Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points ~/input/indices pcl_msgs::msg::Indices reference indices","title":"Input"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#output","text":"Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points","title":"Output"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#parameters","text":"","title":"Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#core-parameters","text":"Name Type Default Value Description filter_limit_min int 0 minimum allowed field value filter_limit_max int 127 maximum allowed field value filter_field_name string \"ring\" filtering field name keep_organized bool false flag to keep indices structure filter_limit_negative bool false flag to return whether the data is inside limit or not","title":"Core Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#optional-referencesexternal-links","text":"","title":"(Optional) References/External links"},{"location":"sensing/pointcloud_preprocessor/docs/passthrough-filter/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/","text":"pointcloud_accumulator # Purpose # The pointcloud_accumulator is a node that accumulates pointclouds for a given amount of time. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points Output # Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points Parameters # Core Parameters # Name Type Default Value Description accumulation_time_sec double 2.0 accumulation period [s] pointcloud_buffer_size int 50 buffer size Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # (Optional) Future extensions / Unimplemented parts #","title":"pointcloud_accumulator"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#pointcloud_accumulator","text":"","title":"pointcloud_accumulator"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#purpose","text":"The pointcloud_accumulator is a node that accumulates pointclouds for a given amount of time.","title":"Purpose"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#input","text":"Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points","title":"Input"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#output","text":"Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points","title":"Output"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#parameters","text":"","title":"Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#core-parameters","text":"Name Type Default Value Description accumulation_time_sec double 2.0 accumulation period [s] pointcloud_buffer_size int 50 buffer size","title":"Core Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#optional-referencesexternal-links","text":"","title":"(Optional) References/External links"},{"location":"sensing/pointcloud_preprocessor/docs/pointcloud-accumulator/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/","text":"vector_map_filter # Purpose # The vector_map_filter is a node that removes points on the outside of lane by using vector map. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points ~/input/vector_map autoware_auto_mapping_msgs::msg::HADMapBin vector map Output # Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points Parameters # Core Parameters # Name Type Default Value Description voxel_size_x double 0.04 voxel size voxel_size_y double 0.04 voxel size Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # (Optional) Future extensions / Unimplemented parts #","title":"vector_map_filter"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#vector_map_filter","text":"","title":"vector_map_filter"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#purpose","text":"The vector_map_filter is a node that removes points on the outside of lane by using vector map.","title":"Purpose"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#input","text":"Name Type Description ~/input/points sensor_msgs::msg::PointCloud2 reference points ~/input/vector_map autoware_auto_mapping_msgs::msg::HADMapBin vector map","title":"Input"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#output","text":"Name Type Description ~/output/points sensor_msgs::msg::PointCloud2 filtered points","title":"Output"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#parameters","text":"","title":"Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#core-parameters","text":"Name Type Default Value Description voxel_size_x double 0.04 voxel size voxel_size_y double 0.04 voxel size","title":"Core Parameters"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#optional-referencesexternal-links","text":"","title":"(Optional) References/External links"},{"location":"sensing/pointcloud_preprocessor/docs/vector-map-filter/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"sensing/tier4_pcl_extensions/","text":"tier4_pcl_extensions # Purpose # The tier4_pcl_extensions is a pcl extension library. The voxel grid filter in this package works with a different algorithm than the original one. Inner-workings / Algorithms # Original Algorithm [1] # create a 3D voxel grid over the input pointcloud data calculate centroid in each voxel all the points are approximated with their centroid Extended Algorithm # create a 3D voxel grid over the input pointcloud data calculate centroid in each voxel all the points are approximated with the closest point to their centroid Inputs / Outputs # Parameters # Assumptions / Known limits # (Optional) Error detection and handling # (Optional) Performance characterization # (Optional) References/External links # [1] https://pointclouds.org/documentation/tutorials/voxel_grid.html (Optional) Future extensions / Unimplemented parts #","title":"tier4_pcl_extensions"},{"location":"sensing/tier4_pcl_extensions/#tier4_pcl_extensions","text":"","title":"tier4_pcl_extensions"},{"location":"sensing/tier4_pcl_extensions/#purpose","text":"The tier4_pcl_extensions is a pcl extension library. The voxel grid filter in this package works with a different algorithm than the original one.","title":"Purpose"},{"location":"sensing/tier4_pcl_extensions/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"sensing/tier4_pcl_extensions/#original-algorithm-1","text":"create a 3D voxel grid over the input pointcloud data calculate centroid in each voxel all the points are approximated with their centroid","title":"Original Algorithm [1]"},{"location":"sensing/tier4_pcl_extensions/#extended-algorithm","text":"create a 3D voxel grid over the input pointcloud data calculate centroid in each voxel all the points are approximated with the closest point to their centroid","title":"Extended Algorithm"},{"location":"sensing/tier4_pcl_extensions/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"sensing/tier4_pcl_extensions/#parameters","text":"","title":"Parameters"},{"location":"sensing/tier4_pcl_extensions/#assumptions-known-limits","text":"","title":"Assumptions / Known limits"},{"location":"sensing/tier4_pcl_extensions/#optional-error-detection-and-handling","text":"","title":"(Optional) Error detection and handling"},{"location":"sensing/tier4_pcl_extensions/#optional-performance-characterization","text":"","title":"(Optional) Performance characterization"},{"location":"sensing/tier4_pcl_extensions/#optional-referencesexternal-links","text":"[1] https://pointclouds.org/documentation/tutorials/voxel_grid.html","title":"(Optional) References/External links"},{"location":"sensing/tier4_pcl_extensions/#optional-future-extensions-unimplemented-parts","text":"","title":"(Optional) Future extensions / Unimplemented parts"},{"location":"simulator/dummy_perception_publisher/","text":"dummy_perception_publisher # Purpose # This node publishes the result of the dummy detection with the type of perception. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description /tf tf2_msgs/TFMessage TF (self-pose) input/object dummy_perception_publisher::msg::Object dummy detection objects Output # Name Type Description output/dynamic_object autoware_perception_msgs::msg::DetectedObjectsWithFeature Publishes objects output/points_raw sensor_msgs::msg::PointCloud2 point cloud of objects Parameters # Name Type Default Value Explanation visible_range double 100.0 sensor visible range [m] detection_successful_rate double 0.8 sensor detection rate. (min) 0.0 - 1.0(max) enable_ray_tracing bool true if True, use ray tracking use_object_recognition bool true if True, publish objects topic Node Parameters # None. Core Parameters # None. Assumptions / Known limits # TBD.","title":"dummy_perception_publisher"},{"location":"simulator/dummy_perception_publisher/#dummy_perception_publisher","text":"","title":"dummy_perception_publisher"},{"location":"simulator/dummy_perception_publisher/#purpose","text":"This node publishes the result of the dummy detection with the type of perception.","title":"Purpose"},{"location":"simulator/dummy_perception_publisher/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"simulator/dummy_perception_publisher/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"simulator/dummy_perception_publisher/#input","text":"Name Type Description /tf tf2_msgs/TFMessage TF (self-pose) input/object dummy_perception_publisher::msg::Object dummy detection objects","title":"Input"},{"location":"simulator/dummy_perception_publisher/#output","text":"Name Type Description output/dynamic_object autoware_perception_msgs::msg::DetectedObjectsWithFeature Publishes objects output/points_raw sensor_msgs::msg::PointCloud2 point cloud of objects","title":"Output"},{"location":"simulator/dummy_perception_publisher/#parameters","text":"Name Type Default Value Explanation visible_range double 100.0 sensor visible range [m] detection_successful_rate double 0.8 sensor detection rate. (min) 0.0 - 1.0(max) enable_ray_tracing bool true if True, use ray tracking use_object_recognition bool true if True, publish objects topic","title":"Parameters"},{"location":"simulator/dummy_perception_publisher/#node-parameters","text":"None.","title":"Node Parameters"},{"location":"simulator/dummy_perception_publisher/#core-parameters","text":"None.","title":"Core Parameters"},{"location":"simulator/dummy_perception_publisher/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"system/autoware_error_monitor/","text":"autoware_error_monitor # Purpose # Autoware Error Monitor has two main functions. It is to judge the system hazard level from the aggregated diagnostic information of each module of Autoware. It enables automatic recovery from the emergency state. Inner-workings / Algorithms # State Transition # updateEmergencyHoldingCondition Flow Chart # Inputs / Outputs # Input # Name Type Description /diagnostics_agg diagnostic_msgs::msg::DiagnosticArray Diagnostic information aggregated based diagnostic_aggregator setting is used to /autoware/state autoware_auto_system_msgs::msg::AutowareState Required to ignore error during Route, Planning and Finalizing. /control/current_gate_mode autoware_control_msgs::msg::GateMode Required to select the appropriate module from autonomous_driving or external_control /vehicle/control_mode autoware_auto_vehicle_msgs::msg::ControlModeReport Required to not hold emergency during manual driving Output # Name Type Description /system/emergency/hazard_status autoware_auto_system_msgs::msg::HazardStatusStamped HazardStatus contains system hazard level, emergency hold status and failure details /diagnostics_err diagnostic_msgs::msg::DiagnosticArray This has the same contents as HazardStatus. This is used for visualization Parameters # Node Parameters # Name Type Default Value Explanation ignore_missing_diagnostics bool false If this parameter is turned off, it will be ignored if required modules have not been received. add_leaf_diagnostics bool true Required to use children diagnostics. diag_timeout_sec double 1.0 (sec) If required diagnostic is not received for a diag_timeout_sec , the diagnostic state become STALE state. data_ready_timeout double 30.0 If input topics required for autoware_error_monitor are not available for data_ready_timeout seconds, autoware_state will translate to emergency state. Core Parameters # Name Type Default Value Explanation hazard_recovery_timeout double 5.0 The vehicle can recovery to normal driving if emergencies disappear during hazard_recovery_timeout . use_emergency_hold bool false If it is false, the vehicle will return to normal as soon as emergencies disappear. use_emergency_hold_in_manual_driving bool false If this parameter is turned off, emergencies will be ignored during manual driving. emergency_hazard_level int 2 If hazard_level is more than emergency_hazard_level, autoware state will translate to emergency state YAML format for autoware_error_monitor # The parameter key should be filled with the hierarchical diagnostics output by diagnostic_aggregator. Parameters prefixed with required_modules.autonomous_driving are for autonomous driving. Parameters with the required_modules.remote_control prefix are for remote control. If the value is default , the default value will be set. Key Type Default Value Explanation required_modules.autonomous_driving.DIAGNOSTIC_NAME.sf_at string \"none\" Diagnostic level where it becomes Safe Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.autonomous_driving.DIAGNOSTIC_NAME.lf_at string \"warn\" Diagnostic level where it becomes Latent Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.autonomous_driving.DIAGNOSTIC_NAME.spf_at string \"error\" Diagnostic level where it becomes Single Point Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.autonomous_driving.DIAGNOSTIC_NAME.auto_recovery string \"true\" Determines whether the system will automatically recover when it recovers from an error. required_modules.remote_control.DIAGNOSTIC_NAME.sf_at string \"none\" Diagnostic level where it becomes Safe Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.remote_control.DIAGNOSTIC_NAME.lf_at string \"warn\" Diagnostic level where it becomes Latent Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.remote_control.DIAGNOSTIC_NAME.spf_at string \"error\" Diagnostic level where it becomes Single Point Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.remote_control.DIAGNOSTIC_NAME.auto_recovery string \"true\" Determines whether the system will automatically recover when it recovers from an error. Assumptions / Known limits # TBD.","title":"autoware_error_monitor"},{"location":"system/autoware_error_monitor/#autoware_error_monitor","text":"","title":"autoware_error_monitor"},{"location":"system/autoware_error_monitor/#purpose","text":"Autoware Error Monitor has two main functions. It is to judge the system hazard level from the aggregated diagnostic information of each module of Autoware. It enables automatic recovery from the emergency state.","title":"Purpose"},{"location":"system/autoware_error_monitor/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"system/autoware_error_monitor/#state-transition","text":"","title":"State Transition"},{"location":"system/autoware_error_monitor/#updateemergencyholdingcondition-flow-chart","text":"","title":"updateEmergencyHoldingCondition Flow Chart"},{"location":"system/autoware_error_monitor/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"system/autoware_error_monitor/#input","text":"Name Type Description /diagnostics_agg diagnostic_msgs::msg::DiagnosticArray Diagnostic information aggregated based diagnostic_aggregator setting is used to /autoware/state autoware_auto_system_msgs::msg::AutowareState Required to ignore error during Route, Planning and Finalizing. /control/current_gate_mode autoware_control_msgs::msg::GateMode Required to select the appropriate module from autonomous_driving or external_control /vehicle/control_mode autoware_auto_vehicle_msgs::msg::ControlModeReport Required to not hold emergency during manual driving","title":"Input"},{"location":"system/autoware_error_monitor/#output","text":"Name Type Description /system/emergency/hazard_status autoware_auto_system_msgs::msg::HazardStatusStamped HazardStatus contains system hazard level, emergency hold status and failure details /diagnostics_err diagnostic_msgs::msg::DiagnosticArray This has the same contents as HazardStatus. This is used for visualization","title":"Output"},{"location":"system/autoware_error_monitor/#parameters","text":"","title":"Parameters"},{"location":"system/autoware_error_monitor/#node-parameters","text":"Name Type Default Value Explanation ignore_missing_diagnostics bool false If this parameter is turned off, it will be ignored if required modules have not been received. add_leaf_diagnostics bool true Required to use children diagnostics. diag_timeout_sec double 1.0 (sec) If required diagnostic is not received for a diag_timeout_sec , the diagnostic state become STALE state. data_ready_timeout double 30.0 If input topics required for autoware_error_monitor are not available for data_ready_timeout seconds, autoware_state will translate to emergency state.","title":"Node Parameters"},{"location":"system/autoware_error_monitor/#core-parameters","text":"Name Type Default Value Explanation hazard_recovery_timeout double 5.0 The vehicle can recovery to normal driving if emergencies disappear during hazard_recovery_timeout . use_emergency_hold bool false If it is false, the vehicle will return to normal as soon as emergencies disappear. use_emergency_hold_in_manual_driving bool false If this parameter is turned off, emergencies will be ignored during manual driving. emergency_hazard_level int 2 If hazard_level is more than emergency_hazard_level, autoware state will translate to emergency state","title":"Core Parameters"},{"location":"system/autoware_error_monitor/#yaml-format-for-autoware_error_monitor","text":"The parameter key should be filled with the hierarchical diagnostics output by diagnostic_aggregator. Parameters prefixed with required_modules.autonomous_driving are for autonomous driving. Parameters with the required_modules.remote_control prefix are for remote control. If the value is default , the default value will be set. Key Type Default Value Explanation required_modules.autonomous_driving.DIAGNOSTIC_NAME.sf_at string \"none\" Diagnostic level where it becomes Safe Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.autonomous_driving.DIAGNOSTIC_NAME.lf_at string \"warn\" Diagnostic level where it becomes Latent Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.autonomous_driving.DIAGNOSTIC_NAME.spf_at string \"error\" Diagnostic level where it becomes Single Point Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.autonomous_driving.DIAGNOSTIC_NAME.auto_recovery string \"true\" Determines whether the system will automatically recover when it recovers from an error. required_modules.remote_control.DIAGNOSTIC_NAME.sf_at string \"none\" Diagnostic level where it becomes Safe Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.remote_control.DIAGNOSTIC_NAME.lf_at string \"warn\" Diagnostic level where it becomes Latent Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.remote_control.DIAGNOSTIC_NAME.spf_at string \"error\" Diagnostic level where it becomes Single Point Fault. Available options are \"none\" , \"warn\" , \"error\" . required_modules.remote_control.DIAGNOSTIC_NAME.auto_recovery string \"true\" Determines whether the system will automatically recover when it recovers from an error.","title":"YAML format for autoware_error_monitor"},{"location":"system/autoware_error_monitor/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"system/autoware_state_monitor/","text":"autoware_state_monitor # Purpose # This node manages AutowareState transitions. Inner-workings / Algorithms # Inputs / Outputs # Input # Name Type Description /planning/mission_planning/route autoware_auto_planning_msgs::msg::HADMapRoute Subscribe route /localization/kinematic_state nav_msgs::msg::Odometry Used to decide whether vehicle is stopped or not /vehicle/state_report autoware_auto_vehicle_msgs::msg::ControlModeReport Used to check vehicle mode: autonomous or manual. Output # Name Type Description /autoware/engage autoware_auto_vehicle_msgs::msg::Engage publish disengage flag on AutowareState transition /autoware/state autoware_auto_system_msgs::msg::AutowareState publish AutowareState Parameters # Node Parameters # Name Type Default Value Explanation update_rate int 10 Timer callback period. Core Parameters # Name Type Default Value Explanation th_arrived_distance_m double 1.0 threshold distance to check if vehicle has arrived at the route's endpoint th_stopped_time_sec double 1.0 threshold time to check if vehicle is stopped th_stopped_velocity_mps double 0.01 threshold velocity to check if vehicle is stopped disengage_on_route bool true send disengage flag or not when the route is subscribed disengage_on_goal bool true send disengage flag or not when the vehicle is arrived goal Assumptions / Known limits # TBD.","title":"autoware_state_monitor"},{"location":"system/autoware_state_monitor/#autoware_state_monitor","text":"","title":"autoware_state_monitor"},{"location":"system/autoware_state_monitor/#purpose","text":"This node manages AutowareState transitions.","title":"Purpose"},{"location":"system/autoware_state_monitor/#inner-workings-algorithms","text":"","title":"Inner-workings / Algorithms"},{"location":"system/autoware_state_monitor/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"system/autoware_state_monitor/#input","text":"Name Type Description /planning/mission_planning/route autoware_auto_planning_msgs::msg::HADMapRoute Subscribe route /localization/kinematic_state nav_msgs::msg::Odometry Used to decide whether vehicle is stopped or not /vehicle/state_report autoware_auto_vehicle_msgs::msg::ControlModeReport Used to check vehicle mode: autonomous or manual.","title":"Input"},{"location":"system/autoware_state_monitor/#output","text":"Name Type Description /autoware/engage autoware_auto_vehicle_msgs::msg::Engage publish disengage flag on AutowareState transition /autoware/state autoware_auto_system_msgs::msg::AutowareState publish AutowareState","title":"Output"},{"location":"system/autoware_state_monitor/#parameters","text":"","title":"Parameters"},{"location":"system/autoware_state_monitor/#node-parameters","text":"Name Type Default Value Explanation update_rate int 10 Timer callback period.","title":"Node Parameters"},{"location":"system/autoware_state_monitor/#core-parameters","text":"Name Type Default Value Explanation th_arrived_distance_m double 1.0 threshold distance to check if vehicle has arrived at the route's endpoint th_stopped_time_sec double 1.0 threshold time to check if vehicle is stopped th_stopped_velocity_mps double 0.01 threshold velocity to check if vehicle is stopped disengage_on_route bool true send disengage flag or not when the route is subscribed disengage_on_goal bool true send disengage flag or not when the vehicle is arrived goal","title":"Core Parameters"},{"location":"system/autoware_state_monitor/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"system/dummy_infrastructure/","text":"dummy_infrastructure # This is a debug node for infrastructure communication. Usage # ros2 launch dummy_infrastructure dummy_infrastructure.launch.xml ros2 run rqt_reconfigure rqt_reconfigure Inputs / Outputs # Inputs # Name Type Description ~/input/command_array autoware_v2x_msgs::msg::InfrastructureCommandArray Infrastructure command Outputs # Name Type Description ~/output/state_array autoware_v2x_msgs::msg::VirtualTrafficLightStateArray Virtual traffic light array Parameters # Node Parameters # Name Type Default Value Explanation update_rate int 10 Timer callback period [Hz] use_first_command bool true Consider instrument id or not instrument_id string `` Used as command id approval bool false set approval filed to ros param is_finalized bool false Stop at stop_line if finalization isn't completed Assumptions / Known limits # TBD.","title":"dummy_infrastructure"},{"location":"system/dummy_infrastructure/#dummy_infrastructure","text":"This is a debug node for infrastructure communication.","title":"dummy_infrastructure"},{"location":"system/dummy_infrastructure/#usage","text":"ros2 launch dummy_infrastructure dummy_infrastructure.launch.xml ros2 run rqt_reconfigure rqt_reconfigure","title":"Usage"},{"location":"system/dummy_infrastructure/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"system/dummy_infrastructure/#inputs","text":"Name Type Description ~/input/command_array autoware_v2x_msgs::msg::InfrastructureCommandArray Infrastructure command","title":"Inputs"},{"location":"system/dummy_infrastructure/#outputs","text":"Name Type Description ~/output/state_array autoware_v2x_msgs::msg::VirtualTrafficLightStateArray Virtual traffic light array","title":"Outputs"},{"location":"system/dummy_infrastructure/#parameters","text":"","title":"Parameters"},{"location":"system/dummy_infrastructure/#node-parameters","text":"Name Type Default Value Explanation update_rate int 10 Timer callback period [Hz] use_first_command bool true Consider instrument id or not instrument_id string `` Used as command id approval bool false set approval filed to ros param is_finalized bool false Stop at stop_line if finalization isn't completed","title":"Node Parameters"},{"location":"system/dummy_infrastructure/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"system/topic_state_monitor/Readme/","text":"topic_state_monitor # Purpose # This node monitors input topic for abnormalities such as timeout and low frequency. The result of topic status is published as diagnostics. Inner-workings / Algorithms # The types of topic status and corresponding diagnostic status are following. Topic status Diagnostic status Description OK OK The topic has no abnormalities NotReceived ERROR The topic has not been received yet WarnRate WARN The frequency of the topic is dropped ErrorRate ERROR The frequency of the topic is significantly dropped Timeout ERROR The topic subscription is stopped for a certain time Inputs / Outputs # Input # Name Type Description any name any type Subscribe target topic to monitor Output # Name Type Description /diagnostics diagnostic_msgs/DiagnosticArray Diagnostics outputs Parameters # Node Parameters # Name Type Default Value Description update_rate double 10.0 Timer callback period [Hz] window_size int 10 Window size of target topic for calculating frequency Core Parameters # Name Type Default Value Description topic string - Name of target topic topic_type string - Type of target topic transient_local bool false QoS policy of topic subscription (Transient Local/Volatile) best_effort bool false QoS policy of topic subscription (Best Effort/Reliable) diag_name string - Name used for the diagnostics to publish warn_rate double 0.5 If the topic rate is lower than this value, the topic status becomes WarnRate error_rate double 0.1 If the topic rate is lower than this value, the topic status becomes ErrorRate timeout double 1.0 If the topic subscription is stopped for more than this time [s], the topic status becomes Timeout Assumptions / Known limits # TBD.","title":"topic_state_monitor"},{"location":"system/topic_state_monitor/Readme/#topic_state_monitor","text":"","title":"topic_state_monitor"},{"location":"system/topic_state_monitor/Readme/#purpose","text":"This node monitors input topic for abnormalities such as timeout and low frequency. The result of topic status is published as diagnostics.","title":"Purpose"},{"location":"system/topic_state_monitor/Readme/#inner-workings-algorithms","text":"The types of topic status and corresponding diagnostic status are following. Topic status Diagnostic status Description OK OK The topic has no abnormalities NotReceived ERROR The topic has not been received yet WarnRate WARN The frequency of the topic is dropped ErrorRate ERROR The frequency of the topic is significantly dropped Timeout ERROR The topic subscription is stopped for a certain time","title":"Inner-workings / Algorithms"},{"location":"system/topic_state_monitor/Readme/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"system/topic_state_monitor/Readme/#input","text":"Name Type Description any name any type Subscribe target topic to monitor","title":"Input"},{"location":"system/topic_state_monitor/Readme/#output","text":"Name Type Description /diagnostics diagnostic_msgs/DiagnosticArray Diagnostics outputs","title":"Output"},{"location":"system/topic_state_monitor/Readme/#parameters","text":"","title":"Parameters"},{"location":"system/topic_state_monitor/Readme/#node-parameters","text":"Name Type Default Value Description update_rate double 10.0 Timer callback period [Hz] window_size int 10 Window size of target topic for calculating frequency","title":"Node Parameters"},{"location":"system/topic_state_monitor/Readme/#core-parameters","text":"Name Type Default Value Description topic string - Name of target topic topic_type string - Type of target topic transient_local bool false QoS policy of topic subscription (Transient Local/Volatile) best_effort bool false QoS policy of topic subscription (Best Effort/Reliable) diag_name string - Name used for the diagnostics to publish warn_rate double 0.5 If the topic rate is lower than this value, the topic status becomes WarnRate error_rate double 0.1 If the topic rate is lower than this value, the topic status becomes ErrorRate timeout double 1.0 If the topic subscription is stopped for more than this time [s], the topic status becomes Timeout","title":"Core Parameters"},{"location":"system/topic_state_monitor/Readme/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"system/velodyne_monitor/Readme/","text":"velodyne_monitor # Purpose # This node monitors the status of Velodyne LiDARs. The result of the status is published as diagnostics. Inner-workings / Algorithms # The status of Velodyne LiDAR can be retrieved from http://[ip_address]/cgi/{info, settings, status, diag}.json . The types of abnormal status and corresponding diagnostics status are following. Abnormal status Diagnostic status No abnormality OK Top board temperature is too cold ERROR Top board temperature is cold WARN Top board temperature is too hot ERROR Top board temperature is hot WARN Bottom board temperature is too cold ERROR Bottom board temperature is cold WARN Bottom board temperature is too hot ERROR Bottom board temperature is hot WARN Rpm(Rotations per minute) of the motor is too low ERROR Rpm(Rotations per minute) of the motor is low WARN Connection error (cannot get Velodyne LiDAR status) ERROR Inputs / Outputs # Input # None Output # Name Type Description /diagnostics diagnostic_msgs/DiagnosticArray Diagnostics outputs Parameters # Node Parameters # Name Type Default Value Description timeout double 0.5 Timeout for HTTP request to get Velodyne LiDAR status [s] Core Parameters # Name Type Default Value Description ip_address string \"192.168.1.201\" IP address of target Velodyne LiDAR temp_cold_warn double -5.0 If the temperature of Velodyne LiDAR is lower than this value, the diagnostics status becomes WARN [\u00b0C] temp_cold_error double -10.0 If the temperature of Velodyne LiDAR is lower than this value, the diagnostics status becomes ERROR [\u00b0C] temp_hot_warn double 75.0 If the temperature of Velodyne LiDAR is higher than this value, the diagnostics status becomes WARN [\u00b0C] temp_hot_error double 80.0 If the temperature of Velodyne LiDAR is higher than this value, the diagnostics status becomes ERROR [\u00b0C] rpm_ratio_warn double 0.80 If the rpm rate of the motor (= current rpm / default rpm) is lower than this value, the diagnostics status becomes WARN rpm_ratio_error double 0.70 If the rpm rate of the motor (= current rpm / default rpm) is lower than this value, the diagnostics status becomes ERROR Assumptions / Known limits # TBD.","title":"velodyne_monitor"},{"location":"system/velodyne_monitor/Readme/#velodyne_monitor","text":"","title":"velodyne_monitor"},{"location":"system/velodyne_monitor/Readme/#purpose","text":"This node monitors the status of Velodyne LiDARs. The result of the status is published as diagnostics.","title":"Purpose"},{"location":"system/velodyne_monitor/Readme/#inner-workings-algorithms","text":"The status of Velodyne LiDAR can be retrieved from http://[ip_address]/cgi/{info, settings, status, diag}.json . The types of abnormal status and corresponding diagnostics status are following. Abnormal status Diagnostic status No abnormality OK Top board temperature is too cold ERROR Top board temperature is cold WARN Top board temperature is too hot ERROR Top board temperature is hot WARN Bottom board temperature is too cold ERROR Bottom board temperature is cold WARN Bottom board temperature is too hot ERROR Bottom board temperature is hot WARN Rpm(Rotations per minute) of the motor is too low ERROR Rpm(Rotations per minute) of the motor is low WARN Connection error (cannot get Velodyne LiDAR status) ERROR","title":"Inner-workings / Algorithms"},{"location":"system/velodyne_monitor/Readme/#inputs-outputs","text":"","title":"Inputs / Outputs"},{"location":"system/velodyne_monitor/Readme/#input","text":"None","title":"Input"},{"location":"system/velodyne_monitor/Readme/#output","text":"Name Type Description /diagnostics diagnostic_msgs/DiagnosticArray Diagnostics outputs","title":"Output"},{"location":"system/velodyne_monitor/Readme/#parameters","text":"","title":"Parameters"},{"location":"system/velodyne_monitor/Readme/#node-parameters","text":"Name Type Default Value Description timeout double 0.5 Timeout for HTTP request to get Velodyne LiDAR status [s]","title":"Node Parameters"},{"location":"system/velodyne_monitor/Readme/#core-parameters","text":"Name Type Default Value Description ip_address string \"192.168.1.201\" IP address of target Velodyne LiDAR temp_cold_warn double -5.0 If the temperature of Velodyne LiDAR is lower than this value, the diagnostics status becomes WARN [\u00b0C] temp_cold_error double -10.0 If the temperature of Velodyne LiDAR is lower than this value, the diagnostics status becomes ERROR [\u00b0C] temp_hot_warn double 75.0 If the temperature of Velodyne LiDAR is higher than this value, the diagnostics status becomes WARN [\u00b0C] temp_hot_error double 80.0 If the temperature of Velodyne LiDAR is higher than this value, the diagnostics status becomes ERROR [\u00b0C] rpm_ratio_warn double 0.80 If the rpm rate of the motor (= current rpm / default rpm) is lower than this value, the diagnostics status becomes WARN rpm_ratio_error double 0.70 If the rpm rate of the motor (= current rpm / default rpm) is lower than this value, the diagnostics status becomes ERROR","title":"Core Parameters"},{"location":"system/velodyne_monitor/Readme/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"},{"location":"vehicle/vehicle_info_util/Readme/","text":"Vehicle Info Util # Purpose # This package is to get vehicle info parameters. Description # Assumptions / Known limits # TBD.","title":"Vehicle Info Util"},{"location":"vehicle/vehicle_info_util/Readme/#vehicle-info-util","text":"","title":"Vehicle Info Util"},{"location":"vehicle/vehicle_info_util/Readme/#purpose","text":"This package is to get vehicle info parameters.","title":"Purpose"},{"location":"vehicle/vehicle_info_util/Readme/#description","text":"","title":"Description"},{"location":"vehicle/vehicle_info_util/Readme/#assumptions-known-limits","text":"TBD.","title":"Assumptions / Known limits"}]}